{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVW8IDqNjyUrDACTfuYnR9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feiyoung/ReadPapers/blob/master/DGL_learn_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLvlvo1_RoRD",
        "outputId": "87ffb28c-f030-439a-ed32-322c2e626132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.3-cp310-cp310-manylinux1_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl\n",
        "#import dgl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO6NTY4JR-ZH",
        "outputId": "004a9489-31ac-4d9d-8dd6-18705410f5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as th"
      ],
      "metadata": {
        "id": "vID19tnySQX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第一章 图\n"
      ],
      "metadata": {
        "id": "PgTLlOqWr-29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#u, v = th.tensor([0, 0, 0, 1]), th.tensor([1, 2, 3, 3])\n",
        "## Define edge using two groups of node IDs.\n",
        "u, v = th.tensor([0,0,0,1]), th.tensor([1,2,3,4])"
      ],
      "metadata": {
        "id": "h6MFmNEdSWuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk5KYSVdSlBL",
        "outputId": "f3b1c7be-f6fa-438f-f764-cafe4f6f2d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = dgl.graph((u, v))"
      ],
      "metadata": {
        "id": "Ql0t6KQKSl65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRxl7INQS9eC",
        "outputId": "d111d61c-e428-431e-e017-f2bb8f13646b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=5, num_edges=4,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the node IDs in the graph\n",
        "print(g.nodes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uc-M8ceTDqh",
        "outputId": "0e03986f-5177-4f02-d52c-ec6a189d24bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the node ID of edges\n",
        "print(g.edges())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqn0Dva6TOwR",
        "outputId": "cd06b1de-bd96-4f52-9d01-b0cbda6a7741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 0, 0, 1]), tensor([1, 2, 3, 4]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access all the node IDs of edges and the IDs of edges\n",
        "print(g.edges(form='all'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvCdiB7rTdUn",
        "outputId": "58e55244-afb5-4ce0-e4f4-b82f936994de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 0, 0, 1]), tensor([1, 2, 3, 4]), tensor([0, 1, 2, 3]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 如果具有最大ID的节点没有边，在创建图的时候，用户需要明确地指明节点的数量。\n",
        "g = dgl.graph((u, v), num_nodes=8)"
      ],
      "metadata": {
        "id": "e0m0p-ZpTqxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKLZAGylTywn",
        "outputId": "8a457636-9310-4cec-a897-d060c904050f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=8, num_edges=4,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g.edges(form='all'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpRDwxHZTzoG",
        "outputId": "259022c2-5290-4bfd-d1ad-cbc96ae6c691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 0, 0, 1]), tensor([1, 2, 3, 4]), tensor([0, 1, 2, 3]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g.nodes()) # Now there are 8 nodes!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "989i_szzT2ta",
        "outputId": "c09197a8-5a0b-4a5c-b053-6f76d05ed8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 对于无向的图，用户需要为每条边都创建两个方向的边。可以使用 dgl.to_bidirected() 函数来实现这个目的。\n",
        "# 如下面的代码段所示，这个函数可以把原图转换成一个包含反向边的图。\n",
        "bg = dgl.to_bidirected(g)"
      ],
      "metadata": {
        "id": "wxXeSpddT8ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bg) # Now there are 8 edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPQr-0R1UJi_",
        "outputId": "b0107423-71fb-40a6-f581-b9044a5f7c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=8, num_edges=8,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bg.edges())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fh0MSW0ULIN",
        "outputId": "facdd95c-bfc5-4b95-e9b2-15dbb4844cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 0, 0, 1, 1, 2, 3, 4]), tensor([1, 2, 3, 0, 4, 0, 0, 1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: 由于Tensor类内部使用C来存储，且显性定义了数据类型以及存储的设备信息，DGL推荐使用Tensor作为DGL API的输入。\n",
        "DGL支持使用 32\n",
        " 位或 64\n",
        " 位的整数作为节点ID和边ID。节点和边ID的数据类型必须一致。如果使用 64\n",
        " 位整数， DGL可以处理最多 263−1\n",
        " 个节点或边。不过，如果图里的节点或者边的数量小于 231−1\n",
        " ，用户最好使用 32\n",
        " 位整数。 这样不仅能提升速度，还能减少内存的使用。DGL提供了进行数据类型转换的方法，如下例所示。"
      ],
      "metadata": {
        "id": "RlnfuBD3UiEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edges = th.tensor([2, 5, 3]), th.tensor([3, 5, 0])  # 边：2->3, 5->5, 3->0\n",
        "g64 = dgl.graph(edges)\n",
        "print(g64.idtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3mYMZvdUTwr",
        "outputId": "934a8e20-6d92-4f8b-ebb5-76d912b740a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g32 = dgl.graph(edges, idtype=th.int32)  # 使用int32构建图\n",
        "print(g32.idtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuyXf8_kVB-B",
        "outputId": "bf468231-3283-499e-aa41-5581641d896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g64_2 = g32.long()  # 转换成int64\n",
        "g64_2.idtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDeDNd4jVI41",
        "outputId": "422f08c6-6278-4f57-acf4-32d5ec5205ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g32_2 = g64.int()  # 转换成int32\n",
        "g32_2.idtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oamwut09VQH8",
        "outputId": "d873bb3e-aeb1-4356-83b1-318bcee4469b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create attributes for nodes and edges of Graph"
      ],
      "metadata": {
        "id": "abx0KzB-WQyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(g.num_nodes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSbKf_4OWc1l",
        "outputId": "4e83a2cc-cf12-4e93-ca01-7e1cb86a67e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.ndata['x'] = th.ones(g.num_nodes(), 3) # each node have a vector [1,1,1] and the attribute name is 'x'"
      ],
      "metadata": {
        "id": "yrkfMNNbVROk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g.edata['x'] = th.ones(g.num_edges(), dtype=th.int32)  # each edge has a scalar 1 and integer type, and the attribute name is 'x'"
      ],
      "metadata": {
        "id": "nKPbWn2dWmr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7ge0nE5Wwgf",
        "outputId": "6e28a1a7-1c93-4469-bb2e-87da592239b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=8, num_edges=4,\n",
            "      ndata_schemes={'x': Scheme(shape=(3,), dtype=torch.float32)}\n",
            "      edata_schemes={'x': Scheme(shape=(), dtype=torch.int32)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.ndata['x'][2] #  # 获取节点2的特征"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgWI-tNmXPoh",
        "outputId": "a7dbee24-3003-48f6-c5e6-10476d9e1e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.ndata['y'] = th.randn(g.num_nodes(), 5) ## Add a new group of attributes named 'y' for nodes."
      ],
      "metadata": {
        "id": "JBfzX-U5W7vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g.edata['x'][th.tensor([0, 3])]  # 获取边0和3的特征"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oxLqaylXM9V",
        "outputId": "2d19e4c3-8957-492d-9051-a35f37738cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "关于 ndata 和 edata 接口的重要说明：仅允许使用数值类型（如单精度浮点型、双精度浮点型和整型）的特征。这些特征可以是标量、向量或多维张量。\n",
        "\n",
        "每个节点特征具有唯一名称，每个边特征也具有唯一名称。节点和边的特征可以具有相同的名称（如上述示例代码中的 'x' ）。\n",
        "\n",
        "通过张量分配创建特征时，DGL会将特征赋给图中的每个节点和每条边。该张量的第一维必须与图中节点或边的数量一致。 不能将特征赋给图中节点或边的子集。\n",
        "\n",
        "相同名称的特征必须具有相同的维度和数据类型。\n",
        "\n",
        "特征张量使用”行优先”的原则，即每个行切片储存1个节点或1条边的特征（参考上述示例代码的第16和18行）。"
      ],
      "metadata": {
        "id": "1lAr1zBtXj0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "对于加权图，用户可以将权重储存为一个边特征，如下。"
      ],
      "metadata": {
        "id": "hRmGhxNSXznU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 边 0->1, 0->2, 0->3, 1->3\n",
        "edges = th.tensor([0, 0, 0, 1]), th.tensor([1, 2, 3, 3])\n",
        "weights = th.tensor([0.1, 0.6, 0.9, 0.7])  # 每条边的权重\n",
        "g = dgl.graph(edges)\n",
        "g.edata['w'] = weights  # 将其命名为 'w'\n",
        "print(g)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkT2GhugXcIh",
        "outputId": "aa234c47-ef6e-4a8f-ba91-c4ef521c5046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=4, num_edges=4,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4 从外部源创建图¶"
      ],
      "metadata": {
        "id": "fiI0w02uYShz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#可以从外部来源构造一个 DGLGraph 对象，包括：\n",
        "# 1.从用于图和稀疏矩阵的外部Python库（NetworkX 和 SciPy）创建而来。\n",
        "# 2. 从磁盘加载图数据。\n",
        "import dgl\n",
        "import torch as th\n",
        "import scipy.sparse as sp\n",
        "spmat = sp.rand(100, 100, density=0.05) # 5%非零项\n",
        "g2 = dgl.from_scipy(spmat)\n",
        "print(g2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w04v_gEVYTwu",
        "outputId": "89aa1934-8434-4966-dc39-3cba789a01b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=100, num_edges=500,\n",
            "      ndata_schemes={}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g2.nodes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW5U2pShYt-Z",
        "outputId": "8320722c-a7f1-4bd7-c3ca-2000fd68d206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
            "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
            "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
            "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g2.edges(form='all'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0GogsmDY3uU",
        "outputId": "e2c1ca10-f6f5-4358-f76d-ae5cc6f14cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([45,  7, 13, 10, 25, 16, 95, 99, 71, 78, 97, 53, 42, 47, 15, 16, 23, 32,\n",
            "        48, 32, 31, 83, 58, 25, 42, 67, 22, 44, 31, 24,  9, 14, 69, 37, 66, 39,\n",
            "         2, 34, 35, 90, 74,  5, 45, 31, 26, 80, 96, 55, 82, 39, 11, 17, 14, 62,\n",
            "        52, 44, 16, 38, 96,  9, 72, 33, 49, 99, 14,  2, 89, 12, 15,  3, 84, 66,\n",
            "        28, 67, 92, 38, 71, 56, 86, 27, 93, 95, 22, 25, 44, 67,  5, 70, 69, 21,\n",
            "        32, 21, 10, 52, 99, 25, 68, 61, 44, 25, 29, 15, 64, 20, 69, 52, 77, 20,\n",
            "        60, 94, 24, 75, 38, 94,  6, 67, 46, 14, 43, 53, 79, 88, 17, 74, 50, 64,\n",
            "        73,  3, 75, 79, 30, 53, 12, 13, 39, 62, 66, 41, 34, 12, 20, 65, 89, 28,\n",
            "        38,  9, 82, 85, 53, 11, 67, 95, 19, 22, 23, 71,  4, 27, 34, 36,  6, 16,\n",
            "        93, 79, 82, 75, 91, 39, 12, 70, 40, 86, 24, 42, 70, 38, 50, 47, 60, 16,\n",
            "        48, 30, 96, 82, 24, 12, 93, 96,  0, 81, 74, 10, 48, 36, 58, 27, 56, 19,\n",
            "        45, 43,  5, 88, 97,  5, 20,  4, 17, 88, 27, 56, 41, 21, 47, 12, 23, 13,\n",
            "        56, 24, 84, 87, 43, 32,  5,  7,  2, 36, 84,  4, 92, 61, 24, 99, 97, 29,\n",
            "        69, 13, 70, 26, 27, 42, 52, 22, 45, 63, 54, 70, 35, 52, 10, 64, 49,  5,\n",
            "        35, 10, 53, 72, 66, 72, 78, 32,  3, 82, 86, 36,  2, 86, 87, 17, 61, 58,\n",
            "        89,  3, 14, 69, 61, 86,  0, 17,  7,  4, 13, 91, 91, 74, 41, 30, 29, 57,\n",
            "        21, 82, 35, 83, 10, 42,  2, 46, 54, 26, 40, 31, 58,  6, 68, 35, 15, 20,\n",
            "        44, 14, 96, 94, 99, 73, 34, 37, 24, 23, 91, 56, 27, 45, 72,  0, 24, 30,\n",
            "        81, 91, 52, 96, 92, 13, 74, 74, 46,  7, 97, 43,  7, 17, 12,  6, 68, 48,\n",
            "        88, 60, 50, 48, 83, 19,  2, 59, 15, 41, 28, 27, 28, 17, 15, 10, 19, 78,\n",
            "        55,  0, 82, 19,  6, 36, 20, 90, 30, 66, 54, 75, 40, 78, 46, 78, 91, 22,\n",
            "        82, 56, 10, 79, 79, 99, 30, 10, 61, 35, 36, 79, 42, 73, 48, 53, 45, 71,\n",
            "        72, 56, 88, 70, 95, 37, 58, 24, 44, 94, 98, 87, 96, 49, 88, 69, 29, 78,\n",
            "        50, 61, 48, 94, 57, 19, 34, 91, 63, 97, 27, 79, 69,  2,  9, 78, 84, 46,\n",
            "        46, 63, 70, 34, 47, 51, 53, 24, 83,  2, 55, 37, 89, 64, 21, 83, 12, 77,\n",
            "        56, 67, 88, 72, 47, 59, 11, 89, 87, 98, 60, 50, 39, 27, 20, 33, 46, 80,\n",
            "        22, 89, 92, 41,  4, 36, 53, 50, 30, 80,  8, 75, 91, 59, 97, 45, 82, 31,\n",
            "        14, 45, 34, 65,  2, 92, 42, 66, 52, 46, 11, 38, 63, 28]), tensor([32, 85, 68, 38, 64, 30, 37,  3, 66, 95, 20, 89, 70, 55, 40, 38, 87, 33,\n",
            "        81, 53, 73, 99, 44, 90, 69, 80, 35,  3, 11, 39, 17, 47,  0, 88, 88, 71,\n",
            "        66, 56,  6, 15, 48,  2, 41, 42, 45,  3,  4, 88, 30, 27, 94, 18, 16, 33,\n",
            "        99, 57, 67, 19, 19, 72, 89, 24, 64, 14, 24,  7, 49, 37, 36,  6, 24, 50,\n",
            "        49, 46, 53, 67, 41,  2, 61, 22, 72, 47, 57, 83, 22, 51, 98,  1, 33, 83,\n",
            "        66, 46, 41, 92, 47, 73, 99, 39, 61, 41, 76, 63, 45, 46, 35, 55, 28, 60,\n",
            "        35, 95, 41, 59, 86, 63, 29, 50, 58, 45,  9, 47, 60, 28, 95, 22, 78, 40,\n",
            "        73, 89, 73, 66, 43, 71, 64, 35, 54, 82, 13,  6, 30, 19, 59, 27, 38, 34,\n",
            "        62, 80,  4, 16, 59, 39, 77, 83, 71,  9, 11, 29, 16, 27, 24, 28, 70, 54,\n",
            "        61, 61, 43, 57, 49, 47, 76, 17, 72, 42, 76, 63, 23, 31, 15, 56, 27,  0,\n",
            "        86, 30, 92, 66, 52, 73, 29, 87, 81, 82, 40, 44, 34, 76, 97, 54, 84, 47,\n",
            "        10, 94, 36, 57, 42, 96, 83, 41, 38, 27, 62, 40, 12, 84, 38, 50, 38, 67,\n",
            "        64, 92, 50, 34,  1, 52, 95, 86, 10, 95, 68, 33, 60, 40, 46,  2, 73, 28,\n",
            "        36, 88, 42, 65, 98, 36, 13, 99, 81, 16,  5,  3, 73, 46, 42, 77, 42, 80,\n",
            "        62, 14, 68, 37, 45, 79, 69, 18,  7, 53, 43, 32,  6, 11, 88, 28, 53, 56,\n",
            "        36,  4, 27,  4, 79, 25, 14, 24, 66, 92, 44, 39, 12, 86, 54, 94, 16, 87,\n",
            "        28, 83, 53, 33, 23, 73, 77, 45, 58, 51, 19, 37, 85, 82, 44, 16, 76, 78,\n",
            "        19, 36, 95, 34, 86, 13, 51, 54,  2, 80, 94, 35, 86, 90,  7, 91,  7, 97,\n",
            "        33, 51, 97,  6,  5, 25, 12, 91, 33, 27, 54, 78, 45, 10, 17,  5, 34, 64,\n",
            "        96, 89, 64, 31, 45, 67, 47, 26,  3, 80, 84, 32, 48, 82,  6, 97, 10, 64,\n",
            "        71, 59, 69, 30, 57, 36, 72, 71, 86,  2, 22, 56, 73, 10, 40, 87, 56,  1,\n",
            "         1, 79,  0, 29, 80, 22, 72, 52, 11, 45, 92, 16, 64, 25, 28, 24, 60, 77,\n",
            "        43, 67,  7, 69, 33, 64, 63, 16, 86, 47, 38, 11, 81, 65,  8,  6, 82,  3,\n",
            "        46, 78, 75, 54, 19, 42, 40, 50,  7, 30, 23, 36, 24, 21, 99, 46, 37, 42,\n",
            "        89,  9, 65, 59, 40, 41, 74, 55, 53, 57, 82, 19, 35, 93, 67, 24, 92, 13,\n",
            "        57, 90, 29, 16, 88, 11, 10, 39, 58, 33, 78, 97, 39, 24, 94, 79, 93, 86,\n",
            "        11, 47, 91, 72, 50, 52, 30, 59, 65, 76, 31, 77, 65,  8, 64, 79, 65, 76,\n",
            "        98, 88, 86, 60,  2, 29, 61, 21,  0, 22, 38, 87, 67, 24]), tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
            "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
            "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
            "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
            "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
            "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
            "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
            "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
            "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
            "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
            "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
            "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
            "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
            "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
            "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
            "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
            "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
            "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
            "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
            "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
            "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
            "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
            "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
            "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
            "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
            "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
            "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
            "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
            "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
            "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
            "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
            "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
            "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
            "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
            "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
            "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "nx_g = nx.path_graph(5) # 一条链路0-1-2-3-4\n",
        "dgl.from_networkx(nx_g) #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Biq0d9Ymi3",
        "outputId": "fe54ea8d-8510-421f-b3cb-8e9a528564b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=5, num_edges=8,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: 注意，当使用 nx.path_graph(5) 进行创建时， DGLGraph 对象有8条边，而非4条。 这是由于 nx.path_graph(5) 构建了一个无向的NetworkX图 networkx.Graph ，而 DGLGraph 的边总是有向的。 所以当将无向的NetworkX图转换为 DGLGraph 对象时，DGL会在内部将1条无向边转换为2条有向边。 使用有向的NetworkX图 networkx.DiGraph 可避免该行为。"
      ],
      "metadata": {
        "id": "Uwwva3sWbUcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nxg = nx.DiGraph([(2, 1), (1, 2), (2, 3), (0, 0)])\n",
        "dgl.from_networkx(nxg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SVlJZMRYtEG",
        "outputId": "f7bb257c-3028-43f8-8e74-e81ffa264945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=4, num_edges=4,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "从磁盘加载图¶\n",
        "有多种文件格式可储存图，所以这里难以枚举所有选项。本节仅给出一些常见格式的一般情况。\n",
        "\n",
        "逗号分隔值（CSV）.CSV是一种常见的格式，以表格格式储存节点、边及其特征："
      ],
      "metadata": {
        "id": "Ndjs2ydsbnuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.5 创建异构图"
      ],
      "metadata": {
        "id": "KhXtxbsic8wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch as th\n",
        "\n",
        "# 创建一个具有3种节点类型和3种边类型的异构图\n",
        "graph_data = {\n",
        "   ('drug', 'interacts', 'drug'): (th.tensor([0, 1]), th.tensor([1, 2])),\n",
        "   ('drug', 'interacts', 'gene'): (th.tensor([0, 1]), th.tensor([2, 3])),\n",
        "   ('drug', 'treats', 'disease'): (th.tensor([1]), th.tensor([2]))\n",
        "}\n",
        "g = dgl.heterograph(graph_data)\n",
        "g.ntypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSpiXBvmbaDu",
        "outputId": "895fde69-f78e-4375-bcb6-4b41cb351aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['disease', 'drug', 'gene']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiNeDUo3dFQR",
        "outputId": "64c6cee9-06d9-41ff-fd83-583644d61d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes={'disease': 3, 'drug': 3, 'gene': 4},\n",
            "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'interacts', 'gene'): 2, ('drug', 'treats', 'disease'): 1},\n",
            "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'gene', 'interacts'), ('drug', 'disease', 'treats')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g.etypes) # print edge types"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0dUa4CcdG3P",
        "outputId": "fb005de3-5fb2-412a-c4fa-5476339a6b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['interacts', 'interacts', 'treats']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g.canonical_etypes) # output the canonical edge types."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4koOdgL_dXcc",
        "outputId": "f582f885-dcb8-40a4-b7e6-3d3df04277a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('drug', 'interacts', 'drug'), ('drug', 'interacts', 'gene'), ('drug', 'treats', 'disease')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: 注意，同构图和二分图只是一种特殊的异构图，它们只包括一种关系。"
      ],
      "metadata": {
        "id": "owBIF71xd-vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 一个同构图\n",
        "dgl.heterograph({('node_type', 'edge_type', 'node_type'): (u, v)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0CGarnvdc5g",
        "outputId": "9c9ae229-7cf0-482f-b66f-393c5b68c0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=5, num_edges=4,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 一个二分图\n",
        "dgl.heterograph({('source_type', 'edge_type', 'destination_type'): (u, v)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PMkTT5ZeHnN",
        "outputId": "502a424f-a20b-4ea1-a086-0784dcb02b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes={'destination_type': 5, 'source_type': 2},\n",
              "      num_edges={('source_type', 'edge_type', 'destination_type'): 4},\n",
              "      metagraph=[('source_type', 'destination_type', 'edge_type')])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "238qpgNceMSM",
        "outputId": "667f945c-3bc3-4a5a-fcc5-c3677fcbfccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes={'disease': 3, 'drug': 3, 'gene': 4},\n",
            "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'interacts', 'gene'): 2, ('drug', 'treats', 'disease'): 1},\n",
            "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'gene', 'interacts'), ('drug', 'disease', 'treats')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(g.metagraph().edges())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJlTKm6SfHcr",
        "outputId": "35a22c10-9e16-4dc5-f193-9cccd5dc2875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('drug', 'drug'), ('drug', 'gene'), ('drug', 'disease')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 当引入多种节点和边类型后，用户在调用DGLGraph API以获取特定类型的信息时，需要指定具体的节点和边类型。此外，不同类型的节点和边具有单独的ID。\n",
        "# 获取图中所有节点的数量\n",
        "g.num_nodes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrzrWR-nfLja",
        "outputId": "ffd27b90-d168-4031-b778-f5e5befec5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取drug节点的数量\n",
        "g.num_nodes('drug')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUuLOo6pfZI3",
        "outputId": "dee3b45d-669b-48bf-88e7-decc649abbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 不同类型的节点有单独的ID。因此，没有指定节点类型就没有明确的返回值。\n",
        "# g.nodes() will produce error"
      ],
      "metadata": {
        "id": "BnqFfHttfa8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g.nodes('drug')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBrHbVzmfezQ",
        "outputId": "2a90e98a-4441-4cda-8942-f32d3a44b63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 为了设置/获取特定节点和边类型的特征，DGL提供了两种新类型的语法：\n",
        "# g.nodes[‘node_type’].data[‘feat_name’] 和 g.edges[‘edge_type’].data[‘feat_name’] 。\n",
        "# 设置/获取\"drug\"类型的节点的\"hv\"特征\n",
        "g.nodes['drug'].data['hv'] = th.ones(3, 1)\n",
        "g.nodes['drug'].data['hv']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgVWsyLUfh5L",
        "outputId": "bcc56c1f-8547-490e-fe5f-a20ec5feebd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置/获取\"treats\"类型的边的\"he\"特征\n",
        "g.edges['treats'].data['he'] = th.zeros(1, 1)\n",
        "g.edges['treats'].data['he']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_cXNbHOf04P",
        "outputId": "10b34edf-7e97-4953-bc4c-243712bb77ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 如果图里只有一种节点或边类型，则不需要指定节点或边的类型。\n",
        "g = dgl.heterograph({\n",
        "   ('drug', 'interacts', 'drug'): (th.tensor([0, 1]), th.tensor([1, 2])),\n",
        "   ('drug', 'is similar', 'drug'): (th.tensor([0, 1]), th.tensor([2, 3]))\n",
        "})\n",
        "g.nodes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NkUBee0f3-Q",
        "outputId": "e710f503-657a-40c6-bee7-82efd17e0b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.ndata['hv'] = th.ones(4, 1)"
      ],
      "metadata": {
        "id": "6bmPOXBWgBzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: 当边类型唯一地确定了源节点和目标节点的类型时，用户可以只使用一个字符串而不是字符串三元组来指定边类型。例如， 对于具有两个关系 ('user', 'plays', 'game') 和 ('user', 'likes', 'game') 的异构图， 只使用 'plays' 或 'like' 来指代这两个关系是可以的。"
      ],
      "metadata": {
        "id": "2RB3ZB9KgjiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "逗号分隔值（CSV）¶\n",
        "一种存储异构图的常见方法是在不同的CSV文件中存储不同类型的节点和边。下面是一个例子。\n"
      ],
      "metadata": {
        "id": "TH2sTQMdgp3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据文件夹\n",
        "data/\n",
        "|-- drug.csv        # drug节点\n",
        "|-- gene.csv        # gene节点\n",
        "|-- disease.csv     # disease节点\n",
        "|-- drug-interact-drug.csv  # drug-drug相互作用边\n",
        "|-- drug-interact-gene.csv  # drug-gene相互作用边\n",
        "|-- drug-treat-disease.csv  # drug-disease治疗边"
      ],
      "metadata": {
        "id": "XTGsxPq3gVPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 边类型子图\n",
        "# 用户可以通过指定要保留的关系来创建异构图的子图，相关的特征也会被拷贝。\n",
        "g = dgl.heterograph({\n",
        "   ('drug', 'interacts', 'drug'): (th.tensor([0, 1]), th.tensor([1, 2])),\n",
        "   ('drug', 'interacts', 'gene'): (th.tensor([0, 1]), th.tensor([2, 3])),\n",
        "   ('drug', 'treats', 'disease'): (th.tensor([1]), th.tensor([2]))\n",
        "})\n",
        "g.nodes['drug'].data['hv'] = th.ones(3, 1)\n",
        "\n",
        "# 保留关系 ('drug', 'interacts', 'drug') 和 ('drug', 'treats', 'disease') 。\n",
        "# 'drug' 和 'disease' 类型的节点也会被保留\n",
        "eg = dgl.edge_type_subgraph(g, [('drug', 'interacts', 'drug'),\n",
        "                                ('drug', 'treats', 'disease')])\n",
        "eg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is7x62INgxKw",
        "outputId": "e48a3ab7-b745-4474-c507-b40bc620da03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes={'disease': 3, 'drug': 3},\n",
              "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'treats', 'disease'): 1},\n",
              "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'disease', 'treats')])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eg.nodes['drug'].data['hv']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaHKkocFhCNW",
        "outputId": "415d65ac-618b-4d8c-e443-19390beed2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 出于建模的目的，用户可能需要将一些关系合并，并对它们应用相同的操作。为了实现这一目的，可以先抽取异构图的边类型子图，然后将该子图转换为同构图。\n",
        "g = dgl.heterograph({\n",
        "   ('drug', 'interacts', 'drug'): (th.tensor([0, 1]), th.tensor([1, 2])),\n",
        "   ('drug', 'interacts', 'gene'): (th.tensor([0, 1]), th.tensor([2, 3])),\n",
        "   ('drug', 'treats', 'disease'): (th.tensor([1]), th.tensor([2]))\n",
        "})\n",
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84T0B8rhhEh3",
        "outputId": "d0b54f00-cec0-4275-86e0-52da37e4ebd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes={'disease': 3, 'drug': 3, 'gene': 4},\n",
            "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'interacts', 'gene'): 2, ('drug', 'treats', 'disease'): 1},\n",
            "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'gene', 'interacts'), ('drug', 'disease', 'treats')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_g = dgl.edge_type_subgraph(g, [('drug', 'interacts', 'drug'),\n",
        "                                   ('drug', 'interacts', 'gene')])\n",
        "h_sub_g = dgl.to_homogeneous(sub_g)\n",
        "print(h_sub_g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsS3mhA0iNm1",
        "outputId": "cfee56c8-cda3-41f2-e3b2-2e62b4b862b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=7, num_edges=4,\n",
            "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)}\n",
            "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64), '_TYPE': Scheme(shape=(), dtype=torch.int64)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_sub_g.nodes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Vkr00DiVXV",
        "outputId": "cab99478-7616-4ab7-f921-2b3c863b89bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_sub_g.edges()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gbJTCZ4icOu",
        "outputId": "866c4600-1323-403c-d64c-3581f6e61b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 0, 1]), tensor([1, 2, 5, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_sub_g.ndata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSv9ZWwwifNl",
        "outputId": "dbe04b69-0940-4dd4-8dc8-b2df6aeca62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_ID': tensor([0, 1, 2, 0, 1, 2, 3]), '_TYPE': tensor([0, 0, 0, 1, 1, 1, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_sub_g.edata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7hvnSohij5H",
        "outputId": "94c8c45f-5632-4c69-b384-97ce4091627b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_ID': tensor([0, 1, 0, 1]), '_TYPE': tensor([0, 0, 1, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.6 在GPU上使用DGLGraph¶"
      ],
      "metadata": {
        "id": "nwC26YL3izJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 用户可以通过在构造过程中传入两个GPU张量来创建GPU上的 DGLGraph 。\n",
        "# 另一种方法是使用 to() API将 DGLGraph 复制到GPU，这会将图结构和特征数据都拷贝到指定的设备。\n",
        "import dgl\n",
        "import torch as th\n",
        "u, v = th.tensor([0, 1, 2]), th.tensor([2, 3, 4])\n",
        "g = dgl.graph((u, v))\n",
        "g.ndata['x'] = th.randn(5, 3)   # 原始特征在CPU上\n",
        "g.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp-B096diqsb",
        "outputId": "49790b63-85f8-4358-8e46-2c4952cf2508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if th.cuda.is_available():\n",
        "    device = th.device('cuda')\n",
        "else:\n",
        "    device = th.device('cpu')\n",
        "\n",
        "print('Using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9bc7XIuj2oq",
        "outputId": "ec70090f-9ffa-4e64-8e4c-4ad6befc71e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install dgl-cu102"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnic059ejuOB",
        "outputId": "06d3068b-bd10-4ce8-f415-7f233a2925d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement dgl-cu102 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for dgl-cu102\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## the colab's cuda is called \"cuda:0\"\n",
        "cuda_g = g.to('cuda:0')         # 接受来自后端框架的任何设备对象\n",
        "cuda_g.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKS1emIrjFar",
        "outputId": "3eda68c7-d20a-432a-d8f0-1345b0edb375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 由GPU张量构造的图也在GPU上\n",
        "u, v = u.to('cuda:0'), v.to('cuda:0')\n",
        "g = dgl.graph((u, v))\n",
        "g.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSfFXIJyjJ0o",
        "outputId": "5977c038-6b0c-40b9-c99c-970400f074c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 任何涉及GPU图的操作都是在GPU上运行的。因此，这要求所有张量参数都已经放在GPU上，其结果(图或张量)也将在GPU上。\n",
        "# 此外，GPU图只接受GPU上的特征数据。\n",
        "cuda_g\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPwSfAjtkyTo",
        "outputId": "8b94c1ac-d43c-42d8-fbf2-705f925ba631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=5, num_edges=3,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# g.in_degrees()\n",
        "g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EaDEVHolLVU",
        "outputId": "30d2b0f3-8d70-4d4d-91cc-f9da544cbed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=5, num_edges=3,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cuda_g.in_edges([2, 3, 4])\n",
        "# cuda_g.in_edges(th.tensor([2, 3, 4]).to('cuda:0'))  #"
      ],
      "metadata": {
        "id": "tZ0d8Y5SmuzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i0o8EsNim0hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第5章：训练图神经网络"
      ],
      "metadata": {
        "id": "q3htvU0sD5J-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 节点分类/回归"
      ],
      "metadata": {
        "id": "Dh-g0ZeGx1gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "\n",
        "dataset = dgl.data.CiteseerGraphDataset()\n",
        "graph = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xi6nTVDEAWc",
        "outputId": "f0b07e3c-be4c-41c1-ef44-d4f5180ef02e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Downloading /root/.dgl/citeseer.zip from https://data.dgl.ai/dataset/citeseer.zip...\n",
            "Extracting file to /root/.dgl/citeseer_d6836239\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6_vwFJkEDbt",
        "outputId": "74e0f2be-8b45-47b1-a3d1-6303935a2339"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=3327, num_edges=9228,\n",
            "      ndata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'label': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(3703,), dtype=torch.float32)}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs_3Px33EU-1",
        "outputId": "69b06005-4851-4b92-8bc2-55d2ee77dc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dgl.heterograph.DGLGraph"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.random.randint(0, 10, 100)) ## generate 100  integers ranged [0-9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIblafNnE7FE",
        "outputId": "306233ad-c974-43fb-ad2d-c9a10ba007c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 5 4 0 7 1 9 9 9 2 0 8 1 1 1 1 2 8 9 5 8 5 8 9 9 7 4 1 1 0 0 5 4 6 1 8\n",
            " 5 0 6 9 2 3 6 9 5 1 3 7 6 1 5 8 7 5 2 2 5 7 5 3 4 5 5 2 8 4 8 1 5 7 4 3 2\n",
            " 0 5 0 9 2 9 8 9 0 0 8 4 2 6 4 8 3 4 8 9 4 8 5 9 1 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IY4RnUtpEWRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hetero_graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A01nrQoyFc3e",
        "outputId": "dd003072-8f7a-4e1b-aafa-9429d884a8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes={'item': 500, 'user': 1000},\n",
            "      num_edges={('item', 'clicked-by', 'user'): 5000, ('item', 'disliked-by', 'user'): 500, ('user', 'click', 'item'): 5000, ('user', 'dislike', 'item'): 500, ('user', 'follow', 'user'): 3000, ('user', 'followed-by', 'user'): 3000},\n",
            "      metagraph=[('item', 'user', 'clicked-by'), ('item', 'user', 'disliked-by'), ('user', 'item', 'click'), ('user', 'item', 'dislike'), ('user', 'user', 'follow'), ('user', 'user', 'followed-by')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建一个2层的GNN模型\n",
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super().__init__()\n",
        "        # 实例化SAGEConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregator_type是聚合函数的类型\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        # 输入是节点的特征\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(graph, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "32wFZP7CFeiY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAGE"
      ],
      "metadata": {
        "id": "w5K0m_Bh9KAu",
        "outputId": "3f27fea7-b1d7-45b6-d5f5-deb90374ce3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.SAGE"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzFXEhf_GdDb",
        "outputId": "817a6224-c9b9-4c2b-9134-4838d5ed106b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=3327, num_edges=9228,\n",
            "      ndata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'label': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(3703,), dtype=torch.float32)}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_features = graph.ndata['feat']\n",
        "node_labels = graph.ndata['label']\n",
        "train_mask = graph.ndata['train_mask']\n",
        "valid_mask = graph.ndata['val_mask']\n",
        "test_mask = graph.ndata['test_mask']\n",
        "n_features = node_features.shape[1]\n",
        "n_labels = int(node_labels.max().item() + 1)"
      ],
      "metadata": {
        "id": "2oEB8FnZGVXp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, graph, features, labels, mask):\n",
        "    model.eval() # Sets the model to evaluation mode. In PyTorch, this is important because it disables operations like dropout,\n",
        "    # which are usually active during training but should be turned off during evaluation.\n",
        "    # This context manager ensures that during the following block of code, PyTorch won't track operations for gradient computation.\n",
        "    # This is done for efficiency during evaluation since gradients are not needed.\n",
        "    with torch.no_grad():\n",
        "        logits = model(graph, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)"
      ],
      "metadata": {
        "id": "1t3KIGvufZ4Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "S8WGLIhJhWsI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SAGE(in_feats=n_features, hid_feats=100, out_feats=n_labels)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "for epoch in range(500):\n",
        "  # Puts the model in training mode. This is necessary because some layers,\n",
        "  # like dropout or batch normalization, behave differently during training compared to evaluation.\n",
        "    model.train() # set model to training mode: compute the grad autoly for parameters\n",
        "    # 使用所有节点(全图)进行前向传播计算\n",
        "    logits = model(graph, node_features)\n",
        "    # 计算损失值\n",
        "    loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
        "    # 计算验证集的准确度\n",
        "    acc = evaluate(model, graph, node_features, node_labels, valid_mask)\n",
        "    # 进行反向传播计算\n",
        "    # Clears the gradients of all optimized tensors. This is necessary before computing the gradients for the next minibatch.\n",
        "    opt.zero_grad()\n",
        "    # Backward pass to compute the gradients of the loss with respect to the model parameters.\n",
        "    loss.backward()\n",
        "    # Updates the model parameters based on the computed gradients using the optimization algorithm (assumed to be stored in the opt variable).\n",
        "    opt.step()\n",
        "    # Prints the value of the training loss for the current epoch.\n",
        "    if(epoch % 50 ==0):\n",
        "      print(loss.item())\n",
        "\n",
        "    # 如果需要的话，保存训练好的模型。本例中省略。"
      ],
      "metadata": {
        "id": "wwwgeg4dgm1L",
        "outputId": "db590117-9902-479d-d25f-55c18a7727ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.792499303817749\n",
            "0.7453944683074951\n",
            "0.16209319233894348\n",
            "0.05643106997013092\n",
            "0.02895241416990757\n",
            "0.01785055361688137\n",
            "0.012196316383779049\n",
            "0.008899891749024391\n",
            "0.006799372378736734\n",
            "0.005373336840420961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss) #\n",
        "print(loss.item())\n",
        "print(evaluate(model, graph, node_features, node_labels, valid_mask))"
      ],
      "metadata": {
        "id": "jzPlr-Uuj82x",
        "outputId": "18ab1656-abf1-417e-f7d0-a10fe4b9d62a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
            "0.004375432152301073\n",
            "0.662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test\n",
        "evaluate(model, graph, node_features, node_labels, test_mask)"
      ],
      "metadata": {
        "id": "Haq9cDayj9gj",
        "outputId": "1078f5c4-ceb1-4ab8-d5bd-e9636095e166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.657"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "异构图上的节点分类模型的训练"
      ],
      "metadata": {
        "id": "eWoXMqzSyTzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How to create a heter graph\n",
        "import dgl\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "n_users = 1000\n",
        "n_items = 500\n",
        "## two nodes type\n",
        "n_follows = 3000\n",
        "n_clicks = 5000\n",
        "n_dislikes = 500\n",
        "## three relation types\n",
        "n_hetero_features = 10\n",
        "n_user_classes = 5\n",
        "n_max_clicks = 10\n",
        "\n",
        "follow_src = np.random.randint(0, n_users, n_follows)\n",
        "follow_dst = np.random.randint(0, n_users, n_follows)\n",
        "click_src = np.random.randint(0, n_users, n_clicks)\n",
        "click_dst = np.random.randint(0, n_items, n_clicks)\n",
        "dislike_src = np.random.randint(0, n_users, n_dislikes)\n",
        "dislike_dst = np.random.randint(0, n_items, n_dislikes)\n",
        "\n",
        "hetero_graph = dgl.heterograph({\n",
        "    ('user', 'follow', 'user'): (follow_src, follow_dst),\n",
        "    ('user', 'followed-by', 'user'): (follow_dst, follow_src),\n",
        "    ('user', 'click', 'item'): (click_src, click_dst),\n",
        "    ('item', 'clicked-by', 'user'): (click_dst, click_src),\n",
        "    ('user', 'dislike', 'item'): (dislike_src, dislike_dst),\n",
        "    ('item', 'disliked-by', 'user'): (dislike_dst, dislike_src)})\n",
        "\n",
        "hetero_graph.nodes['user'].data['feature'] = torch.randn(n_users, n_hetero_features)\n",
        "hetero_graph.nodes['item'].data['feature'] = torch.randn(n_items, n_hetero_features)\n",
        "hetero_graph.nodes['user'].data['label'] = torch.randint(0, n_user_classes, (n_users,))\n",
        "hetero_graph.edges['click'].data['label'] = torch.randint(1, n_max_clicks, (n_clicks,)).float()\n",
        "# 在user类型的节点和click类型的边上随机生成训练集的掩码\n",
        "hetero_graph.nodes['user'].data['train_mask'] = torch.zeros(n_users, dtype=torch.bool).bernoulli(0.6)\n",
        "hetero_graph.edges['click'].data['train_mask'] = torch.zeros(n_clicks, dtype=torch.bool).bernoulli(0.6)\n"
      ],
      "metadata": {
        "id": "ixzUwFLIzKso"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Heterograph Conv model\n",
        "\n",
        "class RGCN(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
        "        super().__init__()\n",
        "        # 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型\n",
        "        self.conv1 = dglnn.HeteroGraphConv({\n",
        "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
        "            for rel in rel_names}, aggregate='sum')\n",
        "        self.conv2 = dglnn.HeteroGraphConv({\n",
        "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
        "            for rel in rel_names}, aggregate='sum')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        # 输入是节点的特征字典\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = {k: F.relu(v) for k, v in h.items()}\n",
        "        h = self.conv2(graph, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "ZsuWYAaLko_4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hetero_graph.etypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur3N55eDasm3",
        "outputId": "08126b1d-39f8-4884-f62e-c1b83f50f3b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['clicked-by', 'disliked-by', 'click', 'dislike', 'follow', 'followed-by']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RGCN(n_hetero_features, 20, n_user_classes, hetero_graph.etypes)\n",
        "user_feats = hetero_graph.nodes['user'].data['feature']\n",
        "item_feats = hetero_graph.nodes['item'].data['feature']\n",
        "labels = hetero_graph.nodes['user'].data['label']\n",
        "train_mask = hetero_graph.nodes['user'].data['train_mask']"
      ],
      "metadata": {
        "id": "a_FwqBoPywkg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用户可以简单地按如下形式进行前向传播计算：\n",
        "node_features = {'user': user_feats, 'item': item_feats}\n",
        "h_dict = model(hetero_graph, node_features)\n",
        "h_user = h_dict['user']\n",
        "h_item = h_dict['item']\n",
        "print(h_item)\n",
        "print(h_user)"
      ],
      "metadata": {
        "id": "yhCgNCUvy0Y2",
        "outputId": "74faaf9f-6dcf-4769-e4f2-9d970e3709f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0575,  0.6067, -0.0424,  0.2786,  1.0782],\n",
            "        [-0.5531, -0.2752,  0.1740, -0.3414,  0.1866],\n",
            "        [-0.1681, -0.1661, -0.0463,  0.0045, -0.1572],\n",
            "        ...,\n",
            "        [-0.5999, -0.0726, -0.1106, -0.2612,  0.2400],\n",
            "        [-0.0139,  0.7908, -1.2675, -0.8072,  0.3811],\n",
            "        [-0.1872, -0.1866, -0.3842, -0.0780, -0.4704]], grad_fn=<SumBackward1>)\n",
            "tensor([[-0.6181,  1.3472,  0.8948, -0.1486,  0.9954],\n",
            "        [ 0.2136, -0.2236,  1.4053,  1.5777, -0.1048],\n",
            "        [-0.4757,  0.9316,  2.4770,  0.8157,  1.1059],\n",
            "        ...,\n",
            "        [-0.5110,  1.3694, -0.3583,  1.0716,  0.5826],\n",
            "        [-0.1496,  1.4201, -0.3755,  0.7165,  0.1973],\n",
            "        [-0.7551,  0.8209, -0.0413,  0.9648,  0.1524]], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 异构图上模型的训练和同构图的模型训练是一样的，只是这里使用了一个包括节点表示的字典来计算预测值。\n",
        "# 例如，如果只预测 user 节点的类别，用户可以从返回的字典中提取 user 的节点嵌入。\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    # 使用所有节点的特征进行前向传播计算，并提取输出的user节点嵌入\n",
        "    logits = model(hetero_graph, node_features)['user']\n",
        "    # 计算损失值\n",
        "    loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "    # 计算验证集的准确度。在本例中省略。\n",
        "    # 进行反向传播计算\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    print(f'The traning loss is: {loss.item(): 4.0f}')\n"
      ],
      "metadata": {
        "id": "3hcqEhDKy6kG",
        "outputId": "4656e1ba-c56a-4a26-8268-9cb638f79718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The traning loss is:    2\n",
            "The traning loss is:    2\n",
            "The traning loss is:    2\n",
            "The traning loss is:    2\n",
            "The traning loss is:    2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 链接预测"
      ],
      "metadata": {
        "id": "AHkgyR2i8Fqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "class DotProductPredictor(nn.Module):\n",
        "    def forward(self, graph, h):\n",
        "        # h是从5.1节的GNN模型中计算出的节点表示\n",
        "        with graph.local_scope():\n",
        "            graph.ndata['h'] = h\n",
        "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            return graph.edata['score']"
      ],
      "metadata": {
        "id": "Yx95PMZV8Hn6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_negative_graph(graph, k):\n",
        "    src, dst = graph.edges()\n",
        "\n",
        "    neg_src = src.repeat_interleave(k)\n",
        "    neg_dst = torch.randint(0, graph.num_nodes(), (len(src) * k,))\n",
        "    return dgl.graph((neg_src, neg_dst), num_nodes=graph.num_nodes())"
      ],
      "metadata": {
        "id": "6v_74MZx8KhD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super().__init__()\n",
        "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
        "        self.pred = DotProductPredictor()\n",
        "    def forward(self, g, neg_g, x):\n",
        "        h = self.sage(g, x)\n",
        "        return self.pred(g, h), self.pred(neg_g, h)"
      ],
      "metadata": {
        "id": "r5eFHQon8sLI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(pos_score, neg_score):\n",
        "    # 间隔损失\n",
        "    n_edges = pos_score.shape[0]\n",
        "    return (1 - pos_score.unsqueeze(1) + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
        "\n",
        "node_features = graph.ndata['feat']\n",
        "n_features = node_features.shape[1]\n",
        "k = 5\n",
        "model = Model(n_features, 100, 100)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "for epoch in range(10):\n",
        "    negative_graph = construct_negative_graph(graph, k)\n",
        "    pos_score, neg_score = model(graph, negative_graph, node_features)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    print(loss.item())"
      ],
      "metadata": {
        "id": "LA1qQix0807M",
        "outputId": "8c53748e-8ef6-4e68-cd28-f86789364c18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.998602032661438\n",
            "0.9959600567817688\n",
            "0.9929999709129333\n",
            "0.9893460273742676\n",
            "0.9846848845481873\n",
            "0.9791660904884338\n",
            "0.9718270897865295\n",
            "0.9635816812515259\n",
            "0.952874481678009\n",
            "0.9406253695487976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_embeddings = model.sage(graph, node_features)"
      ],
      "metadata": {
        "id": "JCSfs4fJ88dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 第6章 大图随机批次训练"
      ],
      "metadata": {
        "id": "puL6gs8wsRNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 针对节点分类任务的邻居采样训练方法"
      ],
      "metadata": {
        "id": "pR4JoNMVth8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show dgl"
      ],
      "metadata": {
        "id": "2OYHgJOEuOho",
        "outputId": "9c8f65bf-c512-4011-bdfc-b2e744c3a407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: dgl\n",
            "Version: 1.1.3\n",
            "Summary: Deep Graph Library\n",
            "Home-page: https://github.com/dmlc/dgl\n",
            "Author: \n",
            "Author-email: \n",
            "License: APACHE\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: networkx, numpy, psutil, requests, scipy, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "g = graph\n",
        "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(2)\n",
        "#dataloader = dgl.dataloading.DataLoader(g, train_nid_dict, sampler,\n",
        "#    batch_size=1024,shuffle=True,drop_last=False,num_workers=4)"
      ],
      "metadata": {
        "id": "sYrxNQgXsXjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 调整模型以进行小批次训练\n",
        "class TwoLayerGCN(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.GraphConv(in_features, hidden_features)\n",
        "        self.conv2 = dglnn.GraphConv(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        x = F.relu(self.conv1(g, x))\n",
        "        x = F.relu(self.conv2(g, x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "udxcugy4wiEE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 然后，用户所需要做的就是用上面生成的块( block )来替换图( g )。\n",
        "class StochasticTwoLayerGCN(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super().__init__()\n",
        "        self.conv1 = dgl.nn.GraphConv(in_features, hidden_features)\n",
        "        self.conv2 = dgl.nn.GraphConv(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, blocks, x):\n",
        "        x = F.relu(self.conv1(blocks[0], x))\n",
        "        x = F.relu(self.conv2(blocks[1], x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "v0a_t7SYwiwa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = StochasticTwoLayerGCN(in_features, hidden_features, out_features)\n",
        "model = model.cuda()\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "for input_nodes, output_nodes, blocks in dataloader:\n",
        "    blocks = [b.to(torch.device('cuda')) for b in blocks]\n",
        "    input_features = blocks[0].srcdata['features']\n",
        "    output_labels = blocks[-1].dstdata['label']\n",
        "    output_predictions = model(blocks, input_features)\n",
        "    loss = compute_loss(output_labels, output_predictions)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()"
      ],
      "metadata": {
        "id": "cN-3SQm1wyiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "完整示例"
      ],
      "metadata": {
        "id": "XYkxMF_mhXey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "nVAfDcjdhvay",
        "outputId": "335003bd-bb61-46fb-d18e-c7316207ebed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ogb"
      ],
      "metadata": {
        "id": "Y9xWYJ-Qh6Yr",
        "outputId": "0ace34e0-93b7-4137-e79e-bd74be5a83c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=d4022d201bc54f776dc401956b915fcbd91310b8f04fe8d0a2b095ccf2406d06\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics.functional as MF\n",
        "import tqdm\n",
        "from dgl.data import AsNodePredDataset\n",
        "from dgl.dataloading import (\n",
        "    DataLoader,\n",
        "    MultiLayerFullNeighborSampler,\n",
        "    NeighborSampler,\n",
        ")\n",
        "from ogb.nodeproppred import DglNodePropPredDataset"
      ],
      "metadata": {
        "id": "g0b9CN63hZPw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_size, hid_size, out_size):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        # three-layer GraphSAGE-mean\n",
        "        self.layers.append(dglnn.SAGEConv(in_size, hid_size, \"mean\"))\n",
        "        self.layers.append(dglnn.SAGEConv(hid_size, hid_size, \"mean\"))\n",
        "        self.layers.append(dglnn.SAGEConv(hid_size, out_size, \"mean\"))\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.hid_size = hid_size\n",
        "        self.out_size = out_size\n",
        "\n",
        "    def forward(self, blocks, x):\n",
        "        h = x\n",
        "        for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
        "            h = layer(block, h)\n",
        "            if l != len(self.layers) - 1:\n",
        "                h = F.relu(h)\n",
        "                h = self.dropout(h)\n",
        "        return h\n",
        "\n",
        "    def inference(self, g, device, batch_size):\n",
        "        \"\"\"Conduct layer-wise inference to get all the node embeddings.\"\"\"\n",
        "        feat = g.ndata[\"feat\"]\n",
        "        sampler = MultiLayerFullNeighborSampler(1, prefetch_node_feats=[\"feat\"])\n",
        "        dataloader = DataLoader(\n",
        "            g,\n",
        "            torch.arange(g.num_nodes()).to(g.device),\n",
        "            sampler,\n",
        "            device=device,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            drop_last=False,\n",
        "            num_workers=0,\n",
        "        )\n",
        "        buffer_device = torch.device(\"cpu\")\n",
        "        pin_memory = buffer_device != device\n",
        "\n",
        "        for l, layer in enumerate(self.layers):\n",
        "            y = torch.empty(\n",
        "                g.num_nodes(),\n",
        "                self.hid_size if l != len(self.layers) - 1 else self.out_size,\n",
        "                dtype=feat.dtype,\n",
        "                device=buffer_device,\n",
        "                pin_memory=pin_memory,\n",
        "            )\n",
        "            feat = feat.to(device)\n",
        "            for input_nodes, output_nodes, blocks in tqdm.tqdm(dataloader):\n",
        "                x = feat[input_nodes]\n",
        "                h = layer(blocks[0], x)  # len(blocks) = 1\n",
        "                if l != len(self.layers) - 1:\n",
        "                    h = F.relu(h)\n",
        "                    h = self.dropout(h)\n",
        "                # by design, our output nodes are contiguous\n",
        "                y[output_nodes[0] : output_nodes[-1] + 1] = h.to(buffer_device)\n",
        "            feat = y\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "Ouk21rw_haKM"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, graph, dataloader, num_classes):\n",
        "    model.eval()\n",
        "    ys = []\n",
        "    y_hats = []\n",
        "    for it, (input_nodes, output_nodes, blocks) in enumerate(dataloader):\n",
        "        with torch.no_grad():\n",
        "            x = blocks[0].srcdata[\"feat\"]\n",
        "            ys.append(blocks[-1].dstdata[\"label\"])\n",
        "            y_hats.append(model(blocks, x))\n",
        "    return MF.accuracy(\n",
        "        torch.cat(y_hats),\n",
        "        torch.cat(ys),\n",
        "        task=\"multiclass\",\n",
        "        num_classes=num_classes,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "xuiDZcVVhdy-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def layerwise_infer(device, graph, nid, model, num_classes, batch_size):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model.inference(\n",
        "            graph, device, batch_size\n",
        "        )  # pred in buffer_device\n",
        "        pred = pred[nid]\n",
        "        label = graph.ndata[\"label\"][nid].to(pred.device)\n",
        "        return MF.accuracy(\n",
        "            pred, label, task=\"multiclass\", num_classes=num_classes\n",
        "        )\n"
      ],
      "metadata": {
        "id": "OsPIHst5hh3m"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(mode, device, g, dataset, model, num_classes):\n",
        "    # create sampler & dataloader\n",
        "    train_idx = dataset.train_idx.to(device)\n",
        "    val_idx = dataset.val_idx.to(device)\n",
        "    sampler = NeighborSampler(\n",
        "        [10, 10, 10],  # fanout for [layer-0, layer-1, layer-2]\n",
        "        prefetch_node_feats=[\"feat\"],\n",
        "        prefetch_labels=[\"label\"],\n",
        "    )\n",
        "    use_uva = mode == \"mixed\"\n",
        "    train_dataloader = DataLoader(\n",
        "        g,\n",
        "        train_idx,\n",
        "        sampler,\n",
        "        device=device,\n",
        "        batch_size=1024,\n",
        "        shuffle=True,\n",
        "        drop_last=False,\n",
        "        num_workers=0,\n",
        "        use_uva=use_uva,\n",
        "    )\n",
        "\n",
        "    val_dataloader = DataLoader(\n",
        "        g,\n",
        "        val_idx,\n",
        "        sampler,\n",
        "        device=device,\n",
        "        batch_size=1024,\n",
        "        shuffle=True,\n",
        "        drop_last=False,\n",
        "        num_workers=0,\n",
        "        use_uva=use_uva,\n",
        "    )\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for it, (input_nodes, output_nodes, blocks) in enumerate(\n",
        "            train_dataloader\n",
        "        ):\n",
        "            x = blocks[0].srcdata[\"feat\"]\n",
        "            y = blocks[-1].dstdata[\"label\"]\n",
        "            y_hat = model(blocks, x)\n",
        "            loss = F.cross_entropy(y_hat, y)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item()\n",
        "        acc = evaluate(model, g, val_dataloader, num_classes)\n",
        "        print(\n",
        "            \"Epoch {:05d} | Loss {:.4f} | Accuracy {:.4f} \".format(\n",
        "                epoch, total_loss / (it + 1), acc.item()\n",
        "            )\n",
        "        )\n"
      ],
      "metadata": {
        "id": "Yz42xKRBhlcL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {'mode': 'mixed'}\n",
        "print(args['mode'])"
      ],
      "metadata": {
        "id": "uCSZlAvCl9Qv",
        "outputId": "2fe5abe2-8fb4-4b31-ff2e-45f92ef67d54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mixed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'mixed'\n",
        "dt = \"bfloat16\"\n",
        "if not torch.cuda.is_available():\n",
        "        mode = \"cpu\"\n",
        "print(f\"Training in {mode} mode.\")\n",
        "\n",
        "# load and preprocess dataset\n",
        "print(\"Loading data\")\n",
        "dataset = AsNodePredDataset(DglNodePropPredDataset(\"ogbn-products\"))\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "FDbMHSx3lbTh",
        "outputId": "69d9ab6a-c267-440f-eeec-ca5b3767928a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training in mixed mode.\n",
            "Loading data\n",
            "This will download 1.38GB. Will you proceed? (y/N)\n",
            "y\n",
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/products.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 1.38 GB: 100%|██████████| 1414/1414 [00:20<00:00, 70.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/products.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into DGL objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-1781eaca9880>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m    \u001b[0;31m# test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'mixed'\n",
        "g = dataset[0]\n",
        "g = g.to(\"cuda\" if mode == \"puregpu\" else \"cpu\")\n",
        "num_classes = dataset.num_classes\n",
        "device = torch.device(\"cpu\" if mode == \"cpu\" else \"cuda\")\n",
        "\n",
        "    # create GraphSAGE model\n",
        "in_size = g.ndata[\"feat\"].shape[1]\n",
        "out_size = dataset.num_classes\n",
        "model = SAGE(in_size, 256, out_size).to(device)\n",
        "\n",
        "    # convert model and graph to bfloat16 if needed\n",
        "if dt == \"bfloat16\":\n",
        "        g = dgl.to_bfloat16(g)\n",
        "        model = model.to(dtype=torch.bfloat16)\n",
        "\n",
        "    # model training\n",
        "print(g)"
      ],
      "metadata": {
        "id": "-cHJRaPSqQXc",
        "outputId": "b2c3d56a-044c-475f-ba09-1cc88ff2fbeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=2449029, num_edges=123718280,\n",
            "      ndata_schemes={'feat': Scheme(shape=(100,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training...\")\n",
        "train(mode, device, g, dataset, model, num_classes)\n",
        "   # test the model\n",
        "print(\"Testing...\")\n",
        "acc = layerwise_infer(\n",
        "        device, g, dataset.test_idx, model, num_classes, batch_size=4096\n",
        "    )\n",
        "print(\"Test Accuracy {:.4f}\".format(acc.item()))"
      ],
      "metadata": {
        "id": "CNWno6wupZLn",
        "outputId": "40f0cffb-a1f9-49f2-ab83-36321036cdb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dgl/dataloading/dataloader.py:1149: DGLWarning: Dataloader CPU affinity opt is not enabled, consider switching it on (see enable_cpu_affinity() or CPU best practices for DGL [https://docs.dgl.ai/tutorials/cpu/cpu_best_practises.html])\n",
            "  dgl_warning(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-0a9ec77a7c2b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m    \u001b[0;31m# test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m acc = layerwise_infer(\n",
            "\u001b[0;32m<ipython-input-49-446b5542d70e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mode, device, g, dataset, model, num_classes)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBackwardCFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FunctionBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFunctionCtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_HookMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# The user should define either backward or vjp but never both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"--mode\",\n",
        "        default=\"mixed\",\n",
        "        choices=[\"cpu\", \"mixed\", \"puregpu\"],\n",
        "        help=\"Training mode. 'cpu' for CPU training, 'mixed' for CPU-GPU mixed training, \"\n",
        "        \"'puregpu' for pure-GPU training.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--dt\",\n",
        "        type=str,\n",
        "        default=\"float\",\n",
        "        help=\"data type(float, bfloat16)\",\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "    if not torch.cuda.is_available():\n",
        "        args.mode = \"cpu\"\n",
        "    print(f\"Training in {args.mode} mode.\")\n",
        "\n",
        "    # load and preprocess dataset\n",
        "    print(\"Loading data\")\n",
        "    dataset = AsNodePredDataset(DglNodePropPredDataset(\"ogbn-products\"))\n",
        "    g = dataset[0]\n",
        "    g = g.to(\"cuda\" if args.mode == \"puregpu\" else \"cpu\")\n",
        "    num_classes = dataset.num_classes\n",
        "    device = torch.device(\"cpu\" if args.mode == \"cpu\" else \"cuda\")\n",
        "\n",
        "    # create GraphSAGE model\n",
        "    in_size = g.ndata[\"feat\"].shape[1]\n",
        "    out_size = dataset.num_classes\n",
        "    model = SAGE(in_size, 256, out_size).to(device)\n",
        "\n",
        "    # convert model and graph to bfloat16 if needed\n",
        "    if args.dt == \"bfloat16\":\n",
        "        g = dgl.to_bfloat16(g)\n",
        "        model = model.to(dtype=torch.bfloat16)\n",
        "\n",
        "    # model training\n",
        "    print(\"Training...\")\n",
        "    train(args, device, g, dataset, model, num_classes)\n",
        "\n",
        "    # test the model\n",
        "    print(\"Testing...\")\n",
        "    acc = layerwise_infer(\n",
        "        device, g, dataset.test_idx, model, num_classes, batch_size=4096\n",
        "    )\n",
        "    print(\"Test Accuracy {:.4f}\".format(acc.item()))"
      ],
      "metadata": {
        "id": "jkZ9HLpFhoIW",
        "outputId": "9168a98c-4526-48ac-90fe-2f493506ece9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--mode {cpu,mixed,puregpu}] [--dt DT]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-62d4f8b3-c678-4378-9fe4-e9c910ea3d22.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.1 异构图上的训练\n"
      ],
      "metadata": {
        "id": "P7WLoSFvshBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 在异构图上训练图神经网络进行节点分类的方法也是类似的。\n",
        "class StochasticTwoLayerRGCN(nn.Module):\n",
        "    def __init__(self, in_feat, hidden_feat, out_feat, rel_names):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.HeteroGraphConv({\n",
        "                rel : dglnn.GraphConv(in_feat, hidden_feat, norm='right')\n",
        "                for rel in rel_names\n",
        "            })\n",
        "        self.conv2 = dglnn.HeteroGraphConv({\n",
        "                rel : dglnn.GraphConv(hidden_feat, out_feat, norm='right')\n",
        "                for rel in rel_names\n",
        "            })\n",
        "\n",
        "    def forward(self, blocks, x):\n",
        "        x = self.conv1(blocks[0], x)\n",
        "        x = self.conv2(blocks[1], x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Kd9tzwnGsgY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(2)\n",
        "#dataloader = dgl.dataloading.DataLoader(g, train_nid_dict, sampler,\n",
        "#    batch_size=1024,shuffle=True,drop_last=False,num_workers=4)"
      ],
      "metadata": {
        "id": "T8vZavCvs_-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 模型的训练与同构图几乎相同。不同之处在于， compute_loss 的实现会包含两个字典：节点类型和预测结果。\n",
        "model = StochasticTwoLayerRGCN(in_features, hidden_features, out_features, etypes)\n",
        "model = model.cuda()\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "for input_nodes, output_nodes, blocks in dataloader:\n",
        "    blocks = [b.to(torch.device('cuda')) for b in blocks]\n",
        "    input_features = blocks[0].srcdata     # returns a dict\n",
        "    output_labels = blocks[-1].dstdata     # returns a dict\n",
        "    output_predictions = model(blocks, input_features)\n",
        "    loss = compute_loss(output_labels, output_predictions)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()"
      ],
      "metadata": {
        "id": "YYrXp3jjtDdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdflib"
      ],
      "metadata": {
        "id": "rOTfvlBBwWR2",
        "outputId": "557f1900-5b15-46a2-ba7d-f93656ccc9fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.6.1 rdflib-7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "实现的案例"
      ],
      "metadata": {
        "id": "viOOGj7auHXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Modeling Relational Data with Graph Convolutional Networks\n",
        "Paper: https://arxiv.org/abs/1703.06103\n",
        "Reference Code: https://github.com/tkipf/relational-gcn\n",
        "\"\"\"\n",
        "import argparse\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "import dgl\n",
        "\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import torch.nn.functional as F\n",
        "from dgl.data.rdf import AIFBDataset, AMDataset, BGSDataset, MUTAGDataset\n",
        "#from model import EntityClassify, RelGraphEmbed"
      ],
      "metadata": {
        "id": "pCIZpdf0uLjz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_embed(node_embed, input_nodes):\n",
        "    emb = {}\n",
        "    for ntype, nid in input_nodes.items():\n",
        "        nid = input_nodes[ntype]\n",
        "        emb[ntype] = node_embed[ntype][nid]\n",
        "    return emb\n"
      ],
      "metadata": {
        "id": "uJr4XrdTuMeJ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(model, loader, node_embed, labels, category, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    count = 0\n",
        "    with loader.enable_cpu_affinity():\n",
        "        for input_nodes, seeds, blocks in loader:\n",
        "            blocks = [blk.to(device) for blk in blocks]\n",
        "            seeds = seeds[category]\n",
        "            emb = extract_embed(node_embed, input_nodes)\n",
        "            emb = {k: e.to(device) for k, e in emb.items()}\n",
        "            lbl = labels[seeds].to(device)\n",
        "            logits = model(emb, blocks)[category]\n",
        "            loss = F.cross_entropy(logits, lbl)\n",
        "            acc = th.sum(logits.argmax(dim=1) == lbl).item()\n",
        "            total_loss += loss.item() * len(seeds)\n",
        "            total_acc += acc\n",
        "            count += len(seeds)\n",
        "    return total_loss / count, total_acc / count\n",
        "\n"
      ],
      "metadata": {
        "id": "OM9UAXOuuRpP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = AIFBDataset()"
      ],
      "metadata": {
        "id": "Q27y9EpBwpuQ",
        "outputId": "7f7ff7a4-e6ce-41e6-b7f2-ed9d80e79ea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/aifb-hetero.zip from https://data.dgl.ai/dataset/rdf/aifb-hetero.zip...\n",
            "Extracting file to /root/.dgl/aifb-hetero_82d021d8\n",
            "Parsing file aifbfixed_complete.n3 ...\n",
            "Processed 0 tuples, found 0 valid tuples.\n",
            "Processed 10000 tuples, found 8406 valid tuples.\n",
            "Processed 20000 tuples, found 16622 valid tuples.\n",
            "Adding reverse edges ...\n",
            "Creating one whole graph ...\n",
            "Total #nodes: 7262\n",
            "Total #edges: 48810\n",
            "Convert to heterograph ...\n",
            "#Node types: 7\n",
            "#Canonical edge types: 104\n",
            "#Unique edge type names: 78\n",
            "Load training/validation/testing split ...\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\n",
        "g = dataset[0]\n",
        "category = dataset.predict_category\n",
        "num_classes = dataset.num_classes\n",
        "train_mask = g.nodes[category].data.pop(\"train_mask\")\n",
        "test_mask = g.nodes[category].data.pop(\"test_mask\")\n",
        "train_idx = th.nonzero(train_mask, as_tuple=False).squeeze()\n",
        "test_idx = th.nonzero(test_mask, as_tuple=False).squeeze()\n",
        "labels = g.nodes[category].data.pop(\"labels\")"
      ],
      "metadata": {
        "id": "wkdLnQJCw10T"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(g)\n",
        "val_idx = train_idx[: len(train_idx) // 5]\n",
        "train_idx = train_idx[len(train_idx) // 5 :]\n",
        "embed_layer = RelGraphEmbed(g, args.n_hidden)\n",
        "labels = labels.to(device)\n",
        "embed_layer = embed_layer.to(device)"
      ],
      "metadata": {
        "id": "8DNZ0ThoxGdY",
        "outputId": "1f7e761f-ea4b-40b5-e446-bd5b1c281328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes={'Forschungsgebiete': 146, 'Forschungsgruppen': 5, 'Kooperationen': 28, 'Personen': 237, 'Projekte': 78, 'Publikationen': 1318, '_Literal': 5450},\n",
            "      num_edges={('Forschungsgebiete', 'ontology#dealtWithIn', 'Projekte'): 357, ('Forschungsgebiete', 'ontology#isWorkedOnBy', 'Personen'): 571, ('Forschungsgebiete', 'ontology#name', '_Literal'): 146, ('Forschungsgebiete', 'rdftype', '_Literal'): 129, ('Forschungsgebiete', 'rev-ontology#isAbout', 'Projekte'): 357, ('Forschungsgebiete', 'rev-ontology#isAbout', 'Publikationen'): 2120, ('Forschungsgruppen', 'ontology#carriesOut', 'Projekte'): 79, ('Forschungsgruppen', 'ontology#head', 'Personen'): 5, ('Forschungsgruppen', 'ontology#homepage', '_Literal'): 5, ('Forschungsgruppen', 'ontology#member', 'Personen'): 74, ('Forschungsgruppen', 'ontology#name', '_Literal'): 5, ('Forschungsgruppen', 'ontology#publishes', 'Publikationen'): 1217, ('Forschungsgruppen', 'rev-ontology#carriedOutBy', 'Projekte'): 79, ('Kooperationen', 'ontology#finances', 'Projekte'): 68, ('Kooperationen', 'ontology#name', '_Literal'): 28, ('Kooperationen', 'rev-ontology#financedBy', 'Projekte'): 65, ('Personen', 'ontology#fax', '_Literal'): 227, ('Personen', 'ontology#homepage', '_Literal'): 78, ('Personen', 'ontology#name', '_Literal'): 227, ('Personen', 'ontology#phone', '_Literal'): 227, ('Personen', 'ontology#photo', '_Literal'): 148, ('Personen', 'ontology#publication', 'Publikationen'): 2609, ('Personen', 'ontology#worksAtProject', 'Projekte'): 200, ('Personen', 'rev-ontology#author', 'Publikationen'): 2550, ('Personen', 'rev-ontology#editor', 'Publikationen'): 81, ('Personen', 'rev-ontology#head', 'Forschungsgruppen'): 5, ('Personen', 'rev-ontology#isWorkedOnBy', 'Forschungsgebiete'): 571, ('Personen', 'rev-ontology#member', 'Forschungsgruppen'): 74, ('Personen', 'rev-ontology#member', 'Projekte'): 265, ('Projekte', 'ontology#carriedOutBy', 'Forschungsgruppen'): 79, ('Projekte', 'ontology#financedBy', 'Kooperationen'): 65, ('Projekte', 'ontology#homepage', '_Literal'): 57, ('Projekte', 'ontology#isAbout', 'Forschungsgebiete'): 357, ('Projekte', 'ontology#member', 'Personen'): 265, ('Projekte', 'ontology#name', '_Literal'): 75, ('Projekte', 'ontology#projectInfo', 'Publikationen'): 952, ('Projekte', 'rev-ontology#carriesOut', 'Forschungsgruppen'): 79, ('Projekte', 'rev-ontology#dealtWithIn', 'Forschungsgebiete'): 357, ('Projekte', 'rev-ontology#finances', 'Kooperationen'): 68, ('Projekte', 'rev-ontology#hasProject', 'Publikationen'): 952, ('Projekte', 'rev-ontology#worksAtProject', 'Personen'): 200, ('Publikationen', 'ontology#abstract', '_Literal'): 534, ('Publikationen', 'ontology#address', '_Literal'): 202, ('Publikationen', 'ontology#author', 'Personen'): 2550, ('Publikationen', 'ontology#author', 'Publikationen'): 1436, ('Publikationen', 'ontology#booktitle', '_Literal'): 765, ('Publikationen', 'ontology#chapter', '_Literal'): 15, ('Publikationen', 'ontology#edition', '_Literal'): 12, ('Publikationen', 'ontology#editor', 'Personen'): 81, ('Publikationen', 'ontology#editor', 'Publikationen'): 109, ('Publikationen', 'ontology#hasProject', 'Projekte'): 952, ('Publikationen', 'ontology#homepage', '_Literal'): 99, ('Publikationen', 'ontology#howpublished', '_Literal'): 49, ('Publikationen', 'ontology#isAbout', 'Forschungsgebiete'): 2120, ('Publikationen', 'ontology#isbn', '_Literal'): 16, ('Publikationen', 'ontology#journal', '_Literal'): 161, ('Publikationen', 'ontology#month', '_Literal'): 759, ('Publikationen', 'ontology#name', '_Literal'): 821, ('Publikationen', 'ontology#note', '_Literal'): 114, ('Publikationen', 'ontology#number', '_Literal'): 145, ('Publikationen', 'ontology#pages', '_Literal'): 548, ('Publikationen', 'ontology#publication', 'Publikationen'): 1554, ('Publikationen', 'ontology#series', '_Literal'): 298, ('Publikationen', 'ontology#title', '_Literal'): 1227, ('Publikationen', 'ontology#type', '_Literal'): 50, ('Publikationen', 'ontology#volume', '_Literal'): 311, ('Publikationen', 'ontology#year', '_Literal'): 1227, ('Publikationen', 'rev-ontology#author', 'Publikationen'): 1436, ('Publikationen', 'rev-ontology#editor', 'Publikationen'): 109, ('Publikationen', 'rev-ontology#projectInfo', 'Projekte'): 952, ('Publikationen', 'rev-ontology#publication', 'Personen'): 2609, ('Publikationen', 'rev-ontology#publication', 'Publikationen'): 1554, ('Publikationen', 'rev-ontology#publishes', 'Forschungsgruppen'): 1217, ('_Literal', 'rev-ontology#abstract', 'Publikationen'): 534, ('_Literal', 'rev-ontology#address', 'Publikationen'): 202, ('_Literal', 'rev-ontology#booktitle', 'Publikationen'): 765, ('_Literal', 'rev-ontology#chapter', 'Publikationen'): 15, ('_Literal', 'rev-ontology#edition', 'Publikationen'): 12, ('_Literal', 'rev-ontology#fax', 'Personen'): 227, ('_Literal', 'rev-ontology#homepage', 'Forschungsgruppen'): 5, ('_Literal', 'rev-ontology#homepage', 'Personen'): 78, ('_Literal', 'rev-ontology#homepage', 'Projekte'): 57, ('_Literal', 'rev-ontology#homepage', 'Publikationen'): 99, ('_Literal', 'rev-ontology#howpublished', 'Publikationen'): 49, ('_Literal', 'rev-ontology#isbn', 'Publikationen'): 16, ('_Literal', 'rev-ontology#journal', 'Publikationen'): 161, ('_Literal', 'rev-ontology#month', 'Publikationen'): 759, ('_Literal', 'rev-ontology#name', 'Forschungsgebiete'): 146, ('_Literal', 'rev-ontology#name', 'Forschungsgruppen'): 5, ('_Literal', 'rev-ontology#name', 'Kooperationen'): 28, ('_Literal', 'rev-ontology#name', 'Personen'): 227, ('_Literal', 'rev-ontology#name', 'Projekte'): 75, ('_Literal', 'rev-ontology#name', 'Publikationen'): 821, ('_Literal', 'rev-ontology#note', 'Publikationen'): 114, ('_Literal', 'rev-ontology#number', 'Publikationen'): 145, ('_Literal', 'rev-ontology#pages', 'Publikationen'): 548, ('_Literal', 'rev-ontology#phone', 'Personen'): 227, ('_Literal', 'rev-ontology#photo', 'Personen'): 148, ('_Literal', 'rev-ontology#series', 'Publikationen'): 298, ('_Literal', 'rev-ontology#title', 'Publikationen'): 1227, ('_Literal', 'rev-ontology#type', 'Publikationen'): 50, ('_Literal', 'rev-ontology#volume', 'Publikationen'): 311, ('_Literal', 'rev-ontology#year', 'Publikationen'): 1227, ('_Literal', 'rev-rdftype', 'Forschungsgebiete'): 129},\n",
            "      metagraph=[('Forschungsgebiete', 'Projekte', 'ontology#dealtWithIn'), ('Forschungsgebiete', 'Projekte', 'rev-ontology#isAbout'), ('Forschungsgebiete', 'Personen', 'ontology#isWorkedOnBy'), ('Forschungsgebiete', '_Literal', 'ontology#name'), ('Forschungsgebiete', '_Literal', 'rdftype'), ('Forschungsgebiete', 'Publikationen', 'rev-ontology#isAbout'), ('Projekte', 'Forschungsgruppen', 'ontology#carriedOutBy'), ('Projekte', 'Forschungsgruppen', 'rev-ontology#carriesOut'), ('Projekte', 'Kooperationen', 'ontology#financedBy'), ('Projekte', 'Kooperationen', 'rev-ontology#finances'), ('Projekte', '_Literal', 'ontology#homepage'), ('Projekte', '_Literal', 'ontology#name'), ('Projekte', 'Forschungsgebiete', 'ontology#isAbout'), ('Projekte', 'Forschungsgebiete', 'rev-ontology#dealtWithIn'), ('Projekte', 'Personen', 'ontology#member'), ('Projekte', 'Personen', 'rev-ontology#worksAtProject'), ('Projekte', 'Publikationen', 'ontology#projectInfo'), ('Projekte', 'Publikationen', 'rev-ontology#hasProject'), ('Personen', '_Literal', 'ontology#fax'), ('Personen', '_Literal', 'ontology#homepage'), ('Personen', '_Literal', 'ontology#name'), ('Personen', '_Literal', 'ontology#phone'), ('Personen', '_Literal', 'ontology#photo'), ('Personen', 'Publikationen', 'ontology#publication'), ('Personen', 'Publikationen', 'rev-ontology#author'), ('Personen', 'Publikationen', 'rev-ontology#editor'), ('Personen', 'Projekte', 'ontology#worksAtProject'), ('Personen', 'Projekte', 'rev-ontology#member'), ('Personen', 'Forschungsgruppen', 'rev-ontology#head'), ('Personen', 'Forschungsgruppen', 'rev-ontology#member'), ('Personen', 'Forschungsgebiete', 'rev-ontology#isWorkedOnBy'), ('_Literal', 'Publikationen', 'rev-ontology#abstract'), ('_Literal', 'Publikationen', 'rev-ontology#address'), ('_Literal', 'Publikationen', 'rev-ontology#booktitle'), ('_Literal', 'Publikationen', 'rev-ontology#chapter'), ('_Literal', 'Publikationen', 'rev-ontology#edition'), ('_Literal', 'Publikationen', 'rev-ontology#homepage'), ('_Literal', 'Publikationen', 'rev-ontology#howpublished'), ('_Literal', 'Publikationen', 'rev-ontology#isbn'), ('_Literal', 'Publikationen', 'rev-ontology#journal'), ('_Literal', 'Publikationen', 'rev-ontology#month'), ('_Literal', 'Publikationen', 'rev-ontology#name'), ('_Literal', 'Publikationen', 'rev-ontology#note'), ('_Literal', 'Publikationen', 'rev-ontology#number'), ('_Literal', 'Publikationen', 'rev-ontology#pages'), ('_Literal', 'Publikationen', 'rev-ontology#series'), ('_Literal', 'Publikationen', 'rev-ontology#title'), ('_Literal', 'Publikationen', 'rev-ontology#type'), ('_Literal', 'Publikationen', 'rev-ontology#volume'), ('_Literal', 'Publikationen', 'rev-ontology#year'), ('_Literal', 'Personen', 'rev-ontology#fax'), ('_Literal', 'Personen', 'rev-ontology#homepage'), ('_Literal', 'Personen', 'rev-ontology#name'), ('_Literal', 'Personen', 'rev-ontology#phone'), ('_Literal', 'Personen', 'rev-ontology#photo'), ('_Literal', 'Forschungsgruppen', 'rev-ontology#homepage'), ('_Literal', 'Forschungsgruppen', 'rev-ontology#name'), ('_Literal', 'Projekte', 'rev-ontology#homepage'), ('_Literal', 'Projekte', 'rev-ontology#name'), ('_Literal', 'Forschungsgebiete', 'rev-ontology#name'), ('_Literal', 'Forschungsgebiete', 'rev-rdftype'), ('_Literal', 'Kooperationen', 'rev-ontology#name'), ('Publikationen', '_Literal', 'ontology#abstract'), ('Publikationen', '_Literal', 'ontology#address'), ('Publikationen', '_Literal', 'ontology#booktitle'), ('Publikationen', '_Literal', 'ontology#chapter'), ('Publikationen', '_Literal', 'ontology#edition'), ('Publikationen', '_Literal', 'ontology#homepage'), ('Publikationen', '_Literal', 'ontology#howpublished'), ('Publikationen', '_Literal', 'ontology#isbn'), ('Publikationen', '_Literal', 'ontology#journal'), ('Publikationen', '_Literal', 'ontology#month'), ('Publikationen', '_Literal', 'ontology#name'), ('Publikationen', '_Literal', 'ontology#note'), ('Publikationen', '_Literal', 'ontology#number'), ('Publikationen', '_Literal', 'ontology#pages'), ('Publikationen', '_Literal', 'ontology#series'), ('Publikationen', '_Literal', 'ontology#title'), ('Publikationen', '_Literal', 'ontology#type'), ('Publikationen', '_Literal', 'ontology#volume'), ('Publikationen', '_Literal', 'ontology#year'), ('Publikationen', 'Personen', 'ontology#author'), ('Publikationen', 'Personen', 'ontology#editor'), ('Publikationen', 'Personen', 'rev-ontology#publication'), ('Publikationen', 'Publikationen', 'ontology#author'), ('Publikationen', 'Publikationen', 'ontology#editor'), ('Publikationen', 'Publikationen', 'ontology#publication'), ('Publikationen', 'Publikationen', 'rev-ontology#author'), ('Publikationen', 'Publikationen', 'rev-ontology#editor'), ('Publikationen', 'Publikationen', 'rev-ontology#publication'), ('Publikationen', 'Projekte', 'ontology#hasProject'), ('Publikationen', 'Projekte', 'rev-ontology#projectInfo'), ('Publikationen', 'Forschungsgebiete', 'ontology#isAbout'), ('Publikationen', 'Forschungsgruppen', 'rev-ontology#publishes'), ('Forschungsgruppen', 'Projekte', 'ontology#carriesOut'), ('Forschungsgruppen', 'Projekte', 'rev-ontology#carriedOutBy'), ('Forschungsgruppen', 'Personen', 'ontology#head'), ('Forschungsgruppen', 'Personen', 'ontology#member'), ('Forschungsgruppen', '_Literal', 'ontology#homepage'), ('Forschungsgruppen', '_Literal', 'ontology#name'), ('Forschungsgruppen', 'Publikationen', 'ontology#publishes'), ('Kooperationen', 'Projekte', 'ontology#finances'), ('Kooperationen', 'Projekte', 'rev-ontology#financedBy'), ('Kooperationen', '_Literal', 'ontology#name')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    # check cuda\n",
        "    device = \"cpu\"\n",
        "    use_cuda = args.gpu >= 0 and th.cuda.is_available()\n",
        "    if use_cuda:\n",
        "        th.cuda.set_device(args.gpu)\n",
        "        device = \"cuda:%d\" % args.gpu\n",
        "\n",
        "    # load graph data\n",
        "    if args.dataset == \"aifb\":\n",
        "        dataset = AIFBDataset()\n",
        "    elif args.dataset == \"mutag\":\n",
        "        dataset = MUTAGDataset()\n",
        "    elif args.dataset == \"bgs\":\n",
        "        dataset = BGSDataset()\n",
        "    elif args.dataset == \"am\":\n",
        "        dataset = AMDataset()\n",
        "    else:\n",
        "        raise ValueError()\n",
        "\n",
        "    g = dataset[0]\n",
        "    category = dataset.predict_category\n",
        "    num_classes = dataset.num_classes\n",
        "    train_mask = g.nodes[category].data.pop(\"train_mask\")\n",
        "    test_mask = g.nodes[category].data.pop(\"test_mask\")\n",
        "    train_idx = th.nonzero(train_mask, as_tuple=False).squeeze()\n",
        "    test_idx = th.nonzero(test_mask, as_tuple=False).squeeze()\n",
        "    labels = g.nodes[category].data.pop(\"labels\")\n",
        "\n",
        "    # split dataset into train, validate, test\n",
        "    if args.validation:\n",
        "        val_idx = train_idx[: len(train_idx) // 5]\n",
        "        train_idx = train_idx[len(train_idx) // 5 :]\n",
        "    else:\n",
        "        val_idx = train_idx\n",
        "\n",
        "    # create embeddings\n",
        "    embed_layer = RelGraphEmbed(g, args.n_hidden)\n",
        "\n",
        "    if not args.data_cpu:\n",
        "        labels = labels.to(device)\n",
        "        embed_layer = embed_layer.to(device)\n",
        "\n",
        "    if args.num_workers <= 0:\n",
        "        raise ValueError(\n",
        "            \"The '--num_workers' parameter value is expected \"\n",
        "            \"to be >0, but got {}.\".format(args.num_workers)\n",
        "        )\n",
        "\n",
        "    node_embed = embed_layer()\n",
        "    # create model\n",
        "    model = EntityClassify(\n",
        "        g,\n",
        "        args.n_hidden,\n",
        "        num_classes,\n",
        "        num_bases=args.n_bases,\n",
        "        num_hidden_layers=args.n_layers - 2,\n",
        "        dropout=args.dropout,\n",
        "        use_self_loop=args.use_self_loop,\n",
        "    )\n",
        "\n",
        "    if use_cuda:\n",
        "        model.cuda()\n",
        "\n",
        "    # train sampler\n",
        "    sampler = dgl.dataloading.MultiLayerNeighborSampler(\n",
        "        [args.fanout] * args.n_layers\n",
        "    )\n",
        "    loader = dgl.dataloading.DataLoader(\n",
        "        g,\n",
        "        {category: train_idx},\n",
        "        sampler,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.num_workers,\n",
        "    )\n",
        "\n",
        "    # validation sampler\n",
        "    # we do not use full neighbor to save computation resources\n",
        "    val_sampler = dgl.dataloading.MultiLayerNeighborSampler(\n",
        "        [args.fanout] * args.n_layers\n",
        "    )\n",
        "    val_loader = dgl.dataloading.DataLoader(\n",
        "        g,\n",
        "        {category: val_idx},\n",
        "        val_sampler,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.num_workers,\n",
        "    )\n",
        "\n",
        "    # optimizer\n",
        "    all_params = itertools.chain(model.parameters(), embed_layer.parameters())\n",
        "    optimizer = th.optim.Adam(all_params, lr=args.lr, weight_decay=args.l2norm)\n",
        "\n",
        "    # training loop\n",
        "    print(\"start training...\")\n",
        "    mean = 0\n",
        "    for epoch in range(args.n_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        if epoch > 3:\n",
        "            t0 = time.time()\n",
        "\n",
        "        with loader.enable_cpu_affinity():\n",
        "            for i, (input_nodes, seeds, blocks) in enumerate(loader):\n",
        "                blocks = [blk.to(device) for blk in blocks]\n",
        "                seeds = seeds[\n",
        "                    category\n",
        "                ]  # we only predict the nodes with type \"category\"\n",
        "                batch_tic = time.time()\n",
        "                emb = extract_embed(node_embed, input_nodes)\n",
        "                lbl = labels[seeds]\n",
        "                if use_cuda:\n",
        "                    emb = {k: e.cuda() for k, e in emb.items()}\n",
        "                    lbl = lbl.cuda()\n",
        "                logits = model(emb, blocks)[category]\n",
        "                loss = F.cross_entropy(logits, lbl)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_acc = th.sum(logits.argmax(dim=1) == lbl).item() / len(\n",
        "                    seeds\n",
        "                )\n",
        "                print(\n",
        "                    f\"Epoch {epoch:05d} | Batch {i:03d} | Train Acc: \"\n",
        "                    \"{train_acc:.4f} | Train Loss: {loss.item():.4f} | Time: \"\n",
        "                    \"{time.time() - batch_tic:.4f}\"\n",
        "                )\n",
        "\n",
        "        if epoch > 3:\n",
        "            mean = (mean * (epoch - 3) + (time.time() - t0)) / (epoch - 2)\n",
        "\n",
        "            val_loss, val_acc = evaluate(\n",
        "                model, val_loader, node_embed, labels, category, device\n",
        "            )\n",
        "            print(\n",
        "                f\"Epoch {epoch:05d} | Valid Acc: {val_acc:.4f} | Valid loss: \"\n",
        "                \"{val_loss:.4f} | Time: {mean:.4f}\"\n",
        "            )\n",
        "    print()\n",
        "    if args.model_path is not None:\n",
        "        th.save(model.state_dict(), args.model_path)\n",
        "\n",
        "    output = model.inference(\n",
        "        g,\n",
        "        args.batch_size,\n",
        "        \"cuda\" if use_cuda else \"cpu\",\n",
        "        args.num_workers,\n",
        "        node_embed,\n",
        "    )\n",
        "    test_pred = output[category][test_idx]\n",
        "    test_labels = labels[test_idx].to(test_pred.device)\n",
        "    test_acc = (test_pred.argmax(1) == test_labels).float().mean()\n",
        "    print(\"Test Acc: {:.4f}\".format(test_acc))\n",
        "    print()"
      ],
      "metadata": {
        "id": "U2BzGF1-uSVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"RGCN\")\n",
        "    parser.add_argument(\n",
        "        \"--dropout\", type=float, default=0, help=\"dropout probability\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--n-hidden\", type=int, default=16, help=\"number of hidden units\"\n",
        "    )\n",
        "    parser.add_argument(\"--gpu\", type=int, default=-1, help=\"gpu\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=1e-2, help=\"learning rate\")\n",
        "    parser.add_argument(\n",
        "        \"--n-bases\",\n",
        "        type=int,\n",
        "        default=-1,\n",
        "        help=\"number of filter weight matrices, default: -1 [use all]\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--n-layers\", type=int, default=2, help=\"number of propagation rounds\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-e\",\n",
        "        \"--n-epochs\",\n",
        "        type=int,\n",
        "        default=20,\n",
        "        help=\"number of training epochs\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"-d\", \"--dataset\", type=str, required=True, help=\"dataset to use\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_path\", type=str, default=None, help=\"path for save the model\"\n",
        "    )\n",
        "    parser.add_argument(\"--l2norm\", type=float, default=0, help=\"l2 norm coef\")\n",
        "    parser.add_argument(\n",
        "        \"--use-self-loop\",\n",
        "        default=False,\n",
        "        action=\"store_true\",\n",
        "        help=\"include self feature as a special relation\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--batch-size\",\n",
        "        type=int,\n",
        "        default=100,\n",
        "        help=\"Mini-batch size. If -1, use full graph training.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--fanout\", type=int, default=4, help=\"Fan-out of neighbor sampling.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--data-cpu\",\n",
        "        action=\"store_true\",\n",
        "        help=\"By default the script puts all node features and labels \"\n",
        "        \"on GPU when using it to save time for data copy. This may \"\n",
        "        \"be undesired if they cannot fit in GPU memory at once. \"\n",
        "        \"This flag disables that.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--num_workers\", type=int, default=4, help=\"Number of node dataloader\"\n",
        "    )\n",
        "\n",
        "    fp = parser.add_mutually_exclusive_group(required=False)\n",
        "    fp.add_argument(\"--validation\", dest=\"validation\", action=\"store_true\")\n",
        "    fp.add_argument(\"--testing\", dest=\"validation\", action=\"store_false\")\n",
        "    parser.set_defaults(validation=True)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "    main(args)"
      ],
      "metadata": {
        "id": "1u1f-veBuXqd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
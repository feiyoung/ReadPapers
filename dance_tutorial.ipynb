{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feiyoung/ReadPapers/blob/master/dance_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installation\n",
        "\n",
        "DANCE is published on [PyPI](https://pypi.org/project/pydance/). Thus, installing DANCE is as easy as\n",
        "\n",
        "```bash\n",
        "pip install pydance\n",
        "```\n",
        "\n",
        "Or, to install the latest dev version on GitHub as\n",
        "\n",
        "```bash\n",
        "pip install git+https://github.com/OmicsML/dance\n",
        "```\n",
        "\n",
        "But becaues DANCE includes many deep learning based methods, there are also deep learning library dependencies, such as [PyTorch](https://pytorch.org/), [PyG](https://www.pyg.org/), and [DGL](https://www.dgl.ai/). We will walk through the installation process below."
      ],
      "metadata": {
        "id": "ugihXw2wU92o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/OmicsML/dance"
      ],
      "metadata": {
        "id": "BzGmi2cGkqKx",
        "outputId": "2cecd966-dbeb-4669-80af-8fdc6fba11b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/OmicsML/dance\n",
            "  Cloning https://github.com/OmicsML/dance to /tmp/pip-req-build-alosdfg8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/OmicsML/dance /tmp/pip-req-build-alosdfg8\n",
            "  Resolved https://github.com/OmicsML/dance to commit 1d94be91625a352ad8510c16d5d23b9ce5e02b53\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting KDEpy (from pydance==1.1.0.dev0)\n",
            "  Downloading KDEpy-1.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (553 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.4/553.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (3.9.0)\n",
            "Collecting igraph (from pydance==1.1.0.dev0)\n",
            "  Downloading igraph-0.11.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting leidenalg (from pydance==1.1.0.dev0)\n",
            "  Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting louvain (from pydance==1.1.0.dev0)\n",
            "  Downloading louvain-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mudata (from pydance==1.1.0.dev0)\n",
            "  Downloading mudata-0.2.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (3.2.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (1.25.2)\n",
            "Collecting omegaconf (from pydance==1.1.0.dev0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (4.8.0.76)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (2.31.0)\n",
            "Collecting scanpy (from pydance==1.1.0.dev0)\n",
            "  Downloading scanpy-1.9.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scib (from pydance==1.1.0.dev0)\n",
            "  Downloading scib-1.1.4-1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (1.2.2)\n",
            "Collecting scikit-misc (from pydance==1.1.0.dev0)\n",
            "  Downloading scikit_misc-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (1.11.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (0.14.1)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (2024.2.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pydance==1.1.0.dev0) (4.66.2)\n",
            "Collecting texttable>=1.6.2 (from igraph->pydance==1.1.0.dev0)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting igraph (from pydance==1.1.0.dev0)\n",
            "  Downloading igraph-0.10.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anndata>=0.8 (from mudata->pydance==1.1.0.dev0)\n",
            "  Downloading anndata-0.10.5.post1-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->pydance==1.1.0.dev0) (0.41.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->pydance==1.1.0.dev0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->pydance==1.1.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->pydance==1.1.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pydance==1.1.0.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pydance==1.1.0.dev0) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pydance==1.1.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pydance==1.1.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pydance==1.1.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pydance==1.1.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy->pydance==1.1.0.dev0) (1.3.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy->pydance==1.1.0.dev0) (3.7.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy->pydance==1.1.0.dev0) (8.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scanpy->pydance==1.1.0.dev0) (23.2)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy->pydance==1.1.0.dev0) (0.5.6)\n",
            "Requirement already satisfied: seaborn>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from scanpy->pydance==1.1.0.dev0) (0.13.1)\n",
            "Collecting session-info (from scanpy->pydance==1.1.0.dev0)\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn>=0.3.10 (from scanpy->pydance==1.1.0.dev0)\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from scib->pydance==1.1.0.dev0) (1.4.2)\n",
            "Collecting deprecated (from scib->pydance==1.1.0.dev0)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from tables->pydance==1.1.0.dev0) (3.0.8)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables->pydance==1.1.0.dev0) (2.9.0)\n",
            "Requirement already satisfied: blosc2~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tables->pydance==1.1.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables->pydance==1.1.0.dev0) (9.0.0)\n",
            "Collecting array-api-compat (from anndata>=0.8->mudata->pydance==1.1.0.dev0)\n",
            "  Downloading array_api_compat-1.4.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->mudata->pydance==1.1.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2~=2.0.0->tables->pydance==1.1.0.dev0) (1.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->pydance==1.1.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->pydance==1.1.0.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->pydance==1.1.0.dev0) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->pydance==1.1.0.dev0) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->pydance==1.1.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy->pydance==1.1.0.dev0) (3.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy->scanpy->pydance==1.1.0.dev0) (1.16.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.3.10->scanpy->pydance==1.1.0.dev0)\n",
            "  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->scib->pydance==1.1.0.dev0) (1.14.1)\n",
            "Collecting stdlib_list (from session-info->scanpy->pydance==1.1.0.dev0)\n",
            "  Downloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pydance, antlr4-python3-runtime, umap-learn, session-info\n",
            "  Building wheel for pydance (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydance: filename=pydance-1.1.0.dev0-py3-none-any.whl size=306370 sha256=4f348b974c4de45008f59e6f3fa5e4dcf366fd11951d84093d2fa04655b1620a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-chwguo0j/wheels/bc/c9/a0/ba3044ec056d128b5cb006463e6c996548dbcab0dd9014548b\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=edfd40cefde0bc8c570f7f2af9d0bfde899c6f729d5e38766de7492d9a8b1adc\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=c053c007781e9b1025fdd45ce1850829311fb6aa3a985cea99a5b78d9e181572\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8027 sha256=4e1cab0d88ca985203f5f15f92af9f2e68fde8da69ff0da71134d1a6aacd2db7\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n",
            "Successfully built pydance antlr4-python3-runtime umap-learn session-info\n",
            "Installing collected packages: texttable, antlr4-python3-runtime, stdlib_list, scikit-misc, omegaconf, igraph, deprecated, array-api-compat, session-info, louvain, leidenalg, KDEpy, pynndescent, anndata, umap-learn, mudata, scanpy, scib, pydance\n",
            "Successfully installed KDEpy-1.1.9 anndata-0.10.5.post1 antlr4-python3-runtime-4.9.3 array-api-compat-1.4.1 deprecated-1.2.14 igraph-0.10.8 leidenalg-0.10.2 louvain-0.8.1 mudata-0.2.3 omegaconf-2.3.0 pydance-1.1.0.dev0 pynndescent-0.5.11 scanpy-1.9.8 scib-1.1.4 scikit-misc-0.3.1 session-info-1.0.0 stdlib_list-0.10.0 texttable-1.7.0 umap-learn-0.5.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "b3d97d2a25f14460bd3221f3733f6ff9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Install torch related dependencies"
      ],
      "metadata": {
        "id": "a9uCJIzekYW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab comes with torch installed, so we do not need to install pytorch here\n",
        "# !pip3 install torch torchvision torchaudio\n",
        "\n",
        "!pip install -q torch_geometric==2.3.1\n",
        "!pip install -q dgl==1.1.0 -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "!pip install -q torchnmf==0.3.4"
      ],
      "metadata": {
        "id": "-9vkgggHU5Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Install DANCE v1.0.0"
      ],
      "metadata": {
        "id": "t0Ai6ohLkpyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydance==1.0.0"
      ],
      "metadata": {
        "id": "xiNfZpuOkewF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Check if DANCE is installed successfully"
      ],
      "metadata": {
        "id": "dPyaIcBPk4FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dance\n",
        "print(f\"Installed DANCE version {dance.__version__}\")"
      ],
      "metadata": {
        "id": "Dwap0oVmk1hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data loading and processing\n",
        "\n",
        "DANCE comes with several benchmarking datasets in a unified dataset object format. This makes data downloading, processing, and caching easy for users through our dataset object interface."
      ],
      "metadata": {
        "id": "qpq3fr_7mkz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Check available data options and load data object"
      ],
      "metadata": {
        "id": "-hPDdWsPpa5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "from pprint import pprint\n",
        "from dance.datasets.singlemodality import ClusteringDataset, ScDeepSortDataset"
      ],
      "metadata": {
        "id": "3oylxVi7oA7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available dataset option for ClusteringDataset:\")\n",
        "pprint(ClusteringDataset.get_available_data())"
      ],
      "metadata": {
        "id": "geQmHab8pnsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available dataset option for ScDeepSortDataset:\")\n",
        "pprint(ScDeepSortDataset.get_available_data())"
      ],
      "metadata": {
        "id": "_3p6UfZHCOES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: ClusteringDataset"
      ],
      "metadata": {
        "id": "1WcWc4dUCSC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ClusteringDataset(\"10X_PBMC\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "wtg5pNZgCdac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The dataset object do not contain data, it only loads the data upon calling\n",
        "# the load_data function\n",
        "data = dataset.load_data()"
      ],
      "metadata": {
        "id": "EhiCX5BpooNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: ScDeepSortDataset"
      ],
      "metadata": {
        "id": "J0b-GAFnCxRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ScDeepSortDataset(species=\"mouse\", tissue=\"Brain\",\n",
        "                            train_dataset=[\"3285\", \"753\"], test_dataset=[\"2695\"])\n",
        "data = dataset.load_data()"
      ],
      "metadata": {
        "id": "00_UOrqlrA_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. A quick primer on AnnData\n",
        "\n",
        "<img\n",
        "  src=\"https://raw.githubusercontent.com/scverse/anndata/main/docs/_static/img/anndata_schema.svg\"\n",
        "  align=\"right\" width=\"450\" alt=\"image\"\n",
        "/>\n",
        "\n",
        "The [dance data object](https://github.com/OmicsML/dance/blob/912405cb5ab43caf16eb22b9216865c7e3976eaf/dance/data/base.py#L40) is heavily built on top of [AnnData](https://anndata.readthedocs.io/en/latest/), which is a widely used data object to represent, store, and manipulate large annotated matrices.\n",
        "\n",
        "> anndata is a Python package for handling annotated data matrices in memory and on disk, positioned between pandas and xarray. anndata offers a broad range of computationally efficient features...\n",
        "\n",
        "AnnData falls into the ecosystem of scVerse, providing extra advantage and ease for handeling single-cell data using, for example, [Scanpy](https://scanpy.readthedocs.io/en/stable/)."
      ],
      "metadata": {
        "id": "cU0EHCYiLzou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dance data object essentially wraps around an AnnData object,\n",
        "which can be accessed in the `.data` attribute."
      ],
      "metadata": {
        "id": "oLrtDujjC-O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adata = data.data\n",
        "print(adata)"
      ],
      "metadata": {
        "id": "glGCQdF0Lx5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cells, num_genes = adata.shape\n",
        "print(f\"There are {num_cells:,} cells and {num_genes:,} genes in this data object.\")"
      ],
      "metadata": {
        "id": "bsBaT1jqEkDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several key attributes in AnnData objects. For example, `.X` typically holds the main data, such as gene expression. `obs` and `obsm` hold metadata for each sample (i.e., a cell)."
      ],
      "metadata": {
        "id": "107dAHfTDOOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adata.X"
      ],
      "metadata": {
        "id": "yJYYK4ZFLxtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adata.obsm[\"cell_type\"]"
      ],
      "metadata": {
        "id": "O5R2Rh_hLxim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Data pre-processing using transforms\n",
        "\n",
        "Applying individual in-place transformations to data\n"
      ],
      "metadata": {
        "id": "0ytH_-HIrNHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scanpy as sc\n",
        "from dance.transforms import AnnDataTransform, FilterGenesPercentile"
      ],
      "metadata": {
        "id": "AYlMut_m02Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Library sizes before normalization: {data.data.X.sum(1).round(0)}\")\n",
        "\n",
        "# Library size normalization\n",
        "AnnDataTransform(sc.pp.normalize_total, target_sum=1e4)(data)\n",
        "\n",
        "print(f\"Library sizes after normalization: {data.data.X.sum(1).round(0)}\")"
      ],
      "metadata": {
        "id": "FhfaqIJP09pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shifted log transformation\n",
        "AnnDataTransform(sc.pp.log1p)(data)\n",
        "\n",
        "print(f\"Sum of expression per cell after log1p transformation: {data.data.X.sum(1)}\")"
      ],
      "metadata": {
        "id": "DZ9nEPA21u55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of genes before filtering: {data.shape[1]:,}\")\n",
        "\n",
        "# Filter out genes that have extreme coefficient of variation\n",
        "FilterGenesPercentile(min_val=1, max_val=99, mode=\"sum\")(data)\n",
        "\n",
        "print(f\"Number of genes before filtering: {data.shape[1]:,}\")"
      ],
      "metadata": {
        "id": "EGOxkYn00-ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Composing transformations into a a pre-precoessing pipeline (feat. caching)"
      ],
      "metadata": {
        "id": "2St8ISsAr1_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dance.transforms import Compose\n",
        "\n",
        "preprocessing_pipeline = Compose(\n",
        "    AnnDataTransform(sc.pp.normalize_total, target_sum=1e-4),\n",
        "    AnnDataTransform(sc.pp.log1p),\n",
        "    FilterGenesPercentile(min_val=1, max_val=99, mode=\"sum\"),\n",
        ")\n",
        "\n",
        "# Now we can apply the preprocessing pipeline transformation to our data\n",
        "# data = dataset.load_data()\n",
        "# preprocessing_pipeline(data)\n",
        "\n",
        "# Alternatively, we can also pass the transformation to the loading function\n",
        "data = dataset.load_data(transform=preprocessing_pipeline, cache=True)"
      ],
      "metadata": {
        "id": "NEhY1hTRo_nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reloading the data with cache enabled using the same transformation\n",
        "# before can significantly reduce the data loading and pre-processing\n",
        "# time. Making it easier for researcher to run evaluation with different\n",
        "# configurations many times but with the same pre-processed data\n",
        "data = dataset.load_data(transform=preprocessing_pipeline, cache=True)"
      ],
      "metadata": {
        "id": "9L8DaBvnuRLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Single modality tasks"
      ],
      "metadata": {
        "id": "mkvsZ3K7YSV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Example: ACTINN for Cell Type Annotation\n",
        "\n",
        "#### Model structure\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/singlemodality/mlp_visualization.png)\n",
        "\n",
        "#### Visualization of annotation results\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/singlemodality/cell_type_visualization.png)"
      ],
      "metadata": {
        "id": "YP6RTEfKHAli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "z-eaoyhCGuTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available dataset option for ScDeepSortDataset:\")\n",
        "pprint(ScDeepSortDataset.get_available_data())"
      ],
      "metadata": {
        "id": "bA7PPc2wvM3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from dance.modules.single_modality.cell_type_annotation.actinn import ACTINN\n",
        "from dance.utils import set_seed\n",
        "\n",
        "# Initialize model and get model specific preprocessing pipeline\n",
        "model = ACTINN(hidden_dims=[256, 256], lambd=0.01, device='cuda')\n",
        "preprocessing_pipeline = model.preprocessing_pipeline(normalize=True, filter_genes=True)\n",
        "\n",
        "# Load data and perform necessary preprocessing\n",
        "dataset = ScDeepSortDataset(species=\"mouse\", tissue=\"Brain\",\n",
        "                            train_dataset=[\"3285\", \"753\"], test_dataset=[\"2695\"])\n",
        "data = dataset.load_data(transform=preprocessing_pipeline, cache=True)"
      ],
      "metadata": {
        "id": "wzZBJS2pvM0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate model"
      ],
      "metadata": {
        "id": "eNKJg6sYG0Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain training and testing data\n",
        "x_train, y_train = data.get_train_data(return_type=\"torch\")\n",
        "x_test, y_test = data.get_test_data(return_type=\"torch\")"
      ],
      "metadata": {
        "id": "QW4EgXbwvSKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "id": "6hJhRnGOvSHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "id": "ruA5vKQ-vSEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate model\n",
        "set_seed(42)\n",
        "model.fit(x_train, y_train, lr=0.001, num_epochs=21,\n",
        "          batch_size=1000, print_cost=True)\n",
        "print(f\"ACC: {model.score(x_test, y_test):.4f}\")"
      ],
      "metadata": {
        "id": "VZjdWCOwvVJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.model)"
      ],
      "metadata": {
        "id": "qevK79covVMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Example: GraphSCI for Imputation\n",
        "\n",
        "#### Model structure\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/singlemodality/graphsci_visualization.png)\n",
        "\n",
        "#### Reported results\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/singlemodality/imputation_results_example.png)"
      ],
      "metadata": {
        "id": "APzGBDTSG7e2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "MDO_0RIFHozy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from dance.datasets.singlemodality import ImputationDataset\n",
        "from dance.modules.single_modality.imputation.graphsci import GraphSCI\n",
        "from dance.utils import set_seed\n",
        "\n",
        "# Load data and perform preprocessing\n",
        "set_seed(42)\n",
        "dataloader = ImputationDataset(data_dir='./data', dataset='pbmc_data', train_size=0.9)\n",
        "preprocessing_pipeline = GraphSCI.preprocessing_pipeline(mask=True, mask_rate=0.1)\n",
        "data = dataloader.load_data(transform=preprocessing_pipeline, cache=True)"
      ],
      "metadata": {
        "id": "yxXzPNjSG6jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.data.layers['train_mask']"
      ],
      "metadata": {
        "id": "pTwtpDNcvdYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.data.layers['valid_mask']"
      ],
      "metadata": {
        "id": "Drw8p9_EvdcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate model"
      ],
      "metadata": {
        "id": "R78kh2NvHr7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain training and testing data\n",
        "X, X_raw, g, mask = data.get_x(return_type=\"default\")\n",
        "device = 'cuda:0'\n",
        "X = torch.tensor(X.toarray()).to(device)\n",
        "X_raw = torch.tensor(X_raw.toarray()).to(device)\n",
        "g = g.to(device)\n",
        "train_idx = data.train_idx\n",
        "test_idx = data.test_idx\n",
        "\n",
        "# Train and evaluate model\n",
        "model = GraphSCI(num_cells=X.shape[0], num_genes=X.shape[1],\n",
        "                 dataset='pbmc_data', gpu=0)\n",
        "model.fit(X, X_raw, g, train_idx, mask, n_epochs=10, la=1e-7)\n",
        "model.load_model()\n",
        "imputed_data = model.predict(X, X_raw, g, mask)\n",
        "score = model.score(X_raw, imputed_data, test_idx, mask, metric='RMSE')\n",
        "print(\"RMSE: %.4f\" % score)"
      ],
      "metadata": {
        "id": "jbo4IZIMG7R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Example: scDeepCluster for Clustering\n",
        "\n",
        "#### Model structure\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/singlemodality/scdeepcluster_visualization.png)\n",
        "\n",
        "#### Reported results\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/singlemodality/clustering_results_example.png)"
      ],
      "metadata": {
        "id": "-0QOxl1iHvdY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "7F-WvpQ9H_Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dance.datasets.singlemodality import ClusteringDataset\n",
        "from dance.modules.single_modality.clustering.scdeepcluster import ScDeepCluster\n",
        "from dance.utils import set_seed\n",
        "\n",
        "\n",
        "# Load data and perform necessary preprocessing\n",
        "dataloader = ClusteringDataset('./data', '10X_PBMC')\n",
        "preprocessing_pipeline = ScDeepCluster.preprocessing_pipeline()\n",
        "data = dataloader.load_data(transform=preprocessing_pipeline)"
      ],
      "metadata": {
        "id": "dUF8K64tHv9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate model"
      ],
      "metadata": {
        "id": "Qo6CQAeaICio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs: x, x_raw, n_clusters\n",
        "inputs, y = data.get_train_data()\n",
        "n_clusters = len(np.unique(y))\n",
        "in_dim = inputs[0].shape[1]\n",
        "\n",
        "# Build and train model\n",
        "set_seed(42)\n",
        "model = ScDeepCluster(input_dim=in_dim, z_dim=32, encodeLayer=[256, 64], decodeLayer=[64, 256], device='cuda')\n",
        "model.fit(inputs, y, n_clusters=n_clusters, lr=0.01, epochs=3, pt_epochs=3)\n",
        "\n",
        "# Evaluate model predictions\n",
        "score = model.score(None, y)\n",
        "print(f\"ARI: {score:.4f}\")"
      ],
      "metadata": {
        "id": "74Pkn2ztHwRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Multi-modality tasks"
      ],
      "metadata": {
        "id": "O2CSLVVBIT01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Modality Prediction"
      ],
      "metadata": {
        "id": "ilgPs_VMIa5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task and Model Description\n",
        "\n",
        "Modality Prediction: predicting the flow of information from DNA to RNA and RNA to Protein.\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/multimodality/modality_prediction_visualization.svg)\n",
        "\n",
        "In this section, we take RNA-to-Protein as an example task, where the data are obtained from CITE-seq technology. We use BABEL[1] model as an example to demonstrate the workflow of DANCE package.\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/multimodality/babel_visualization.jpeg)\n",
        "\n",
        "[1] Wu, Kevin E., et al. \"BABEL enables cross-modality translation between multiomic profiles at single-cell resolution.\" Proceedings of the National Academy of Sciences 118.15 (2021): e2023070118."
      ],
      "metadata": {
        "id": "tWUwYvvrJhLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import packages and initializations"
      ],
      "metadata": {
        "id": "G_lWTzJUJuOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "\n",
        "import anndata\n",
        "import mudata\n",
        "import scanpy as sc\n",
        "import torch\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "from dance import logger\n",
        "from dance.data import Data\n",
        "from dance.datasets.multimodality import ModalityPredictionDataset\n",
        "from dance.modules.multi_modality.predict_modality.babel import BabelWrapper\n",
        "from dance.utils import set_seed\n",
        "\n",
        "set_seed(42)\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "OUWrqab2ITLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data and perform necessary preprocessing"
      ],
      "metadata": {
        "id": "p1e1yhinJ0Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ModalityPredictionDataset(\"openproblems_bmmc_cite_phase2_rna_subset\")\n",
        "data = dataset.load_data()"
      ],
      "metadata": {
        "id": "6rY-HCL2IZr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct data object\n",
        "data.set_config(feature_mod=\"mod1\", label_mod=\"mod2\")\n",
        "\n",
        "# Obtain training and testing data\n",
        "x_train, y_train = data.get_train_data(return_type=\"torch\")\n",
        "x_test, y_test = data.get_test_data(return_type=\"torch\")"
      ],
      "metadata": {
        "id": "12b8zfD3IZ-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "LWEhJDOBv43v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Specify hyperparameters and initialize the model"
      ],
      "metadata": {
        "id": "_64BDx2Wv_KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "######## Important hyperparameters\n",
        "parser.add_argument(\"--subtask\", default=\"openproblems_bmmc_cite_phase2_rna_subset\")\n",
        "parser.add_argument(\"--max_epochs\", type=int, default=40)\n",
        "parser.add_argument(\"--lr\", \"-l\", type=float, default=0.01, help=\"Learning rate\")\n",
        "parser.add_argument(\"--batchsize\", \"-b\", type=int, default=64, help=\"Batch size\")\n",
        "parser.add_argument(\"--hidden\", type=int, default=64, help=\"Hidden dimensions\")\n",
        "parser.add_argument(\"--earlystop\", type=int, default=2, help=\"Early stopping after N epochs\")\n",
        "parser.add_argument(\"--naive\", \"-n\", action=\"store_true\", help=\"Use a naive model instead of lego model\")\n",
        "parser.add_argument(\"--lossweight\", type=float, default=1., help=\"Relative loss weight\")\n",
        "########\n",
        "\n",
        "parser.add_argument(\"--model_folder\", default=\"./\")\n",
        "parser.add_argument(\"--outdir\", \"-o\", default=\"./\", help=\"Directory to output to\")\n",
        "parser.add_argument(\"--resume\", action=\"store_true\")\n",
        "parser.add_argument(\"--device\", default=\"cuda\")\n",
        "parser.add_argument(\"--cpus\", default=1, type=int)\n",
        "parser.add_argument(\"--rnd_seed\", default=42, type=int)\n",
        "\n",
        "args_defaults = parser.parse_args([])\n",
        "args = argparse.Namespace(**vars(args_defaults))\n",
        "args"
      ],
      "metadata": {
        "id": "g3DZ7fEqv-21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BabelWrapper(args, dim_in=x_train.shape[1], dim_out=y_train.shape[1])"
      ],
      "metadata": {
        "id": "Ec-fO2V0J6rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate model"
      ],
      "metadata": {
        "id": "XXaT400QJ9or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train.float(), y_train.float(), val_ratio=0.15)"
      ],
      "metadata": {
        "id": "_pSaYI7aJ6o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x_test.float())"
      ],
      "metadata": {
        "id": "yCH4urZsJ6bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_test.float(), y_test.float())"
      ],
      "metadata": {
        "id": "Zqy4zqfQIaAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Modality Matching"
      ],
      "metadata": {
        "id": "z29G7PPcGtjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matching profiles of each cell from different modalities.\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/multimodality/modality_matching_visualization.jpeg)\n",
        "\n",
        "In this section, we take RNA-to-Protein as an example task, where the data are obtained from CITE-seq technology. We use scMoGNN[2] model as an example to demonstrate the workflow of DANCE package.\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/multimodality/scmogcn_visualization.jpeg)\n",
        "\n",
        "[2] Wen, Hongzhi, et al. \"Graph neural networks for multimodal single-cell data integration.\" Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2022."
      ],
      "metadata": {
        "id": "Y5IWp0PHG_xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data and perform necessary preprocessing"
      ],
      "metadata": {
        "id": "ooQd3gmnHIN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dance.datasets.multimodality import ModalityMatchingDataset\n",
        "from dance.modules.multi_modality.match_modality.scmogcn import ScMoGCNWrapper\n",
        "from dance.transforms.graph.cell_feature_graph import CellFeatureBipartiteGraph\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "dataset = ModalityMatchingDataset('openproblems_bmmc_cite_phase2_rna_subset', root='./data', preprocess=\"pca\", pkl_path='lsi_input_pca_count.pkl')\n",
        "data = dataset.load_data()"
      ],
      "metadata": {
        "id": "M8rAJxqLGsTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ScMoGNN graph construction\n",
        "data = CellFeatureBipartiteGraph(cell_feature_channel=\"X_pca\", mod=\"mod1\")(data)\n",
        "data = CellFeatureBipartiteGraph(cell_feature_channel=\"X_pca\", mod=\"mod2\")(data)\n",
        "data.set_config(feature_mod=[\"mod1\", \"mod2\", \"mod1\", \"mod2\"], feature_channel_type=[\"uns\", \"uns\", \"obs\", \"obs\"],\n",
        "                feature_channel=[\"g\", \"g\", \"batch\", \"batch\"], label_mod=\"mod1\", label_channel=\"labels\")"
      ],
      "metadata": {
        "id": "14mocJh3Gsm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(g_mod1, g_mod2, batch_mod1, batch_mod2), z = data.get_data(return_type=\"default\")\n",
        "train_size = len(data.get_split_idx(\"train\"))\n",
        "test_idx = np.arange(train_size, g_mod1.num_nodes(\"cell\"))\n",
        "z_test = F.one_hot(torch.from_numpy(z[train_size:]).long())\n",
        "labels1 = torch.argmax(z_test, dim=0).to(device)\n",
        "labels2 = torch.argmax(z_test, dim=1).to(device)\n",
        "g_mod1 = g_mod1.to(device)\n",
        "g_mod2 = g_mod2.to(device)"
      ],
      "metadata": {
        "id": "muMV5snDGsp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Specify hyperparametsr and initialize the model"
      ],
      "metadata": {
        "id": "a2GZz64qHT-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--layers\", default=4, type=int, choices=[3, 4, 5, 6, 7])\n",
        "parser.add_argument(\"--learning_rate\", default=6e-4, type=float)\n",
        "parser.add_argument(\"--disable_propagation\", default=0, type=int, choices=[0, 1, 2])\n",
        "parser.add_argument(\"--auxiliary_loss\", default=True, type=bool)\n",
        "parser.add_argument(\"--epochs\", default=2000, type=int)\n",
        "parser.add_argument(\"--hidden_size\", default=64, type=int)\n",
        "parser.add_argument(\"--temperature\", default=2.739896, type=float)\n",
        "parser.add_argument(\"--device\", default='cuda', type=str)\n",
        "parser.add_argument(\"--rnd_seed\", default=42, type=int)\n",
        "\n",
        "args_defaults = parser.parse_args([])\n",
        "args = argparse.Namespace(**vars(args_defaults))\n",
        "data_folder = './data/'\n",
        "device = 'cuda'\n",
        "args"
      ],
      "metadata": {
        "id": "jGmectIGGssz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ScMoGCNWrapper(\n",
        "    args,\n",
        "    [\n",
        "        [(g_mod1.num_nodes(\"feature\"), 512, 0.25), (512, 512, 0.25), (512, args.hidden_size)],\n",
        "        [(g_mod2.num_nodes(\"feature\"), 512, 0.2), (512, 512, 0.2), (512, args.hidden_size)],\n",
        "        [(args.hidden_size, 512, 0.2), (512, g_mod1.num_nodes(\"feature\"))],\n",
        "        [(args.hidden_size, 512, 0.2), (512, g_mod2.num_nodes(\"feature\"))],\n",
        "    ],\n",
        "    args.temperature,\n",
        ")"
      ],
      "metadata": {
        "id": "f5plMkDfGsvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate model"
      ],
      "metadata": {
        "id": "_ueVlu-6HYV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(g_mod1, g_mod2, labels1, labels2, train_size=train_size)"
      ],
      "metadata": {
        "id": "BJ9K9YCfGsx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(test_idx, enhance=True, batch1=batch_mod1, batch2=batch_mod2)"
      ],
      "metadata": {
        "id": "PxDuWlKoGs0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(test_idx, labels_matrix=z_test, enhance=True, batch1=batch_mod1, batch2=batch_mod2)"
      ],
      "metadata": {
        "id": "tXwY3LVFGs3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Spatial tasks"
      ],
      "metadata": {
        "id": "Y3Y2XVUyKD40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Spatial Domain"
      ],
      "metadata": {
        "id": "FZS7TIBOKQ3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SpaGCN model for spatial domain identification\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/spatial/spagcn_framework.png)"
      ],
      "metadata": {
        "id": "D0PPLfYdKZNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dance.transforms import Compose\n",
        "from dance.datasets.spatial import SpatialLIBDDataset\n",
        "from dance.modules.spatial.spatial_domain.spagcn import SpaGCN\n",
        "from dance.utils import set_seed\n",
        "from dance.transforms import CellPCA, Compose, FilterGenesMatch, SetConfig\n",
        "from dance.transforms.graph import SpaGCNGraph, SpaGCNGraph2D"
      ],
      "metadata": {
        "id": "gbLBaY5BwRCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize model and get model specific preprocessing *pipeline*"
      ],
      "metadata": {
        "id": "gC8_MNm9Knjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SpaGCN()\n",
        "# In SpaGCN, alpha and beta are used for graph construction\n",
        "preprocessing_pipeline = model.preprocessing_pipeline(alpha=1, beta=49)"
      ],
      "metadata": {
        "id": "Vtl12VGvKQaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### User defined customized transform"
      ],
      "metadata": {
        "id": "MCENWWqAKrEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_pipeline = Compose(\n",
        "    FilterGenesMatch(prefixes=[\"ERCC\", \"MT-\"]),\n",
        "    SpaGCNGraph(alpha=1, beta=49),\n",
        "    SpaGCNGraph2D(),\n",
        "    CellPCA(n_components=40),\n",
        "    SetConfig({\n",
        "        \"feature_channel\": [\"CellPCA\", \"SpaGCNGraph\", \"SpaGCNGraph2D\"],\n",
        "        \"feature_channel_type\": [\"obsm\", \"obsp\", \"obsp\"],\n",
        "        \"label_channel\": \"label\",\n",
        "        \"label_channel_type\": \"obs\"\n",
        "    }),\n",
        ")"
      ],
      "metadata": {
        "id": "j0EXszkKKQXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data and perform necessary preprocessing"
      ],
      "metadata": {
        "id": "8m8cYF5VKwsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = SpatialLIBDDataset(data_id=\"151673\")\n",
        "data = dataloader.load_data(transform=preprocessing_pipeline, cache=True)"
      ],
      "metadata": {
        "id": "616ANzlKwaks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "hfPuJmV0wcmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.data.obsp[\"SpaGCNGraph\"].shape"
      ],
      "metadata": {
        "id": "-ygJh7-TK1Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.x[0].shape"
      ],
      "metadata": {
        "id": "F8Nnkh_NK1A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.x[1].shape"
      ],
      "metadata": {
        "id": "O-_Sj-smK09p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x, adj, adj_2d), y = data.get_train_data()"
      ],
      "metadata": {
        "id": "IYTjlVHswiNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, x.shape"
      ],
      "metadata": {
        "id": "VsHgLCwtwiUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj, adj.shape"
      ],
      "metadata": {
        "id": "Om03IJebwie6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y, y.shape"
      ],
      "metadata": {
        "id": "JvR4xO-8wl8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate model"
      ],
      "metadata": {
        "id": "mGUEFoXLK57h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = model.search_l(0.05, adj, start=0.01, end=1000, tol=5e-3, max_run=200)\n",
        "model.set_l(l)\n",
        "res = model.search_set_res((x, adj), l=l, target_num=7, start=0.4, step=0.1,\n",
        "                           tol=5e-3, lr=0.05, epochs=200, max_run=200)"
      ],
      "metadata": {
        "id": "BJLyTTQyK06z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.fit_predict((x, adj), init_spa=True, init=\"louvain\", tol=5e-3,\n",
        "                         lr=0.05, epochs=200, res=res)"
      ],
      "metadata": {
        "id": "c1fTJ2-vK041"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.default_score_func(y, pred)\n",
        "print(f\"ARI: {score:.4f}\")"
      ],
      "metadata": {
        "id": "bD4PmvfZK04E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Cell Type Deconvolution"
      ],
      "metadata": {
        "id": "9tEEPzblLLf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DSTG model for cell type deconvolution\n",
        "\n",
        "![image](https://github.com/OmicsML/dance-tutorials/raw/main/imgs/tutorial_v1/spatial/dstg_framework.png)"
      ],
      "metadata": {
        "id": "uWeBYQgFLPgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from dance.datasets.spatial import CellTypeDeconvoDataset\n",
        "from dance.modules.spatial.cell_type_deconvo import DSTG\n",
        "from dance.utils import set_seed"
      ],
      "metadata": {
        "id": "JuUBSEx0LWvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get model specific preprocessing *pipeline*"
      ],
      "metadata": {
        "id": "T0Huz17oLbxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_pipeline = DSTG.preprocessing_pipeline(\n",
        "    n_pseudo=500,\n",
        "    n_top_genes=2000,\n",
        "    k_filter=200,\n",
        "    num_cc=30,\n",
        ")"
      ],
      "metadata": {
        "id": "SNewOFwMLcws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data and perform necessary preprocessing"
      ],
      "metadata": {
        "id": "WUuvU7AsLhu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CellTypeDeconvoDataset(data_dir=\"data/spatial\", data_id=\"CARD_synthetic\")\n",
        "data = dataset.load_data(transform=preprocessing_pipeline, cache=True)"
      ],
      "metadata": {
        "id": "M-z7K16wLcPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.x"
      ],
      "metadata": {
        "id": "6bzAub6oK0xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data.x)"
      ],
      "metadata": {
        "id": "lBbjqjkGLnLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.x[0], data.x[0].shape"
      ],
      "metadata": {
        "id": "Y01dDri6LnHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.x[1], data.x[1].shape"
      ],
      "metadata": {
        "id": "kEyieaeILnEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(adj, x), y = data.get_data(return_type=\"default\")\n",
        "x, y = torch.FloatTensor(x), torch.FloatTensor(y.values)\n",
        "adj = torch.sparse.FloatTensor(torch.LongTensor([adj.row.tolist(), adj.col.tolist()]),\n",
        "                               torch.FloatTensor(adj.data.astype(np.int32)))"
      ],
      "metadata": {
        "id": "IyZ1rXFkLnBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, x.shape"
      ],
      "metadata": {
        "id": "nQdWqipvxX_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj, adj.shape"
      ],
      "metadata": {
        "id": "Fp_iEPSPxYCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y, y.shape"
      ],
      "metadata": {
        "id": "0Pss6LONxYFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = data.get_split_mask(\"pseudo\", return_type=\"torch\")\n",
        "inputs = (adj, x, train_mask)\n",
        "train_mask, train_mask.shape"
      ],
      "metadata": {
        "id": "tq0ZmCStxYHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate model"
      ],
      "metadata": {
        "id": "8K4uFzomLrIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DSTG(nhid=16, bias=False, dropout=0, device=\"auto\")\n",
        "pred = model.fit_predict(inputs, y, lr=0.01, max_epochs=25, weight_decay=0.0001)\n",
        "pred, pred.shape"
      ],
      "metadata": {
        "id": "yR-8s8HgxfJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mask = data.get_split_mask(\"test\", return_type=\"torch\")\n",
        "test_mask, test_mask.shape"
      ],
      "metadata": {
        "id": "YPVLCbkXxewS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.default_score_func(y[test_mask], pred[test_mask])\n",
        "print(f\"MSE: {score:7.4f}\")"
      ],
      "metadata": {
        "id": "8GgGkurzLm-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
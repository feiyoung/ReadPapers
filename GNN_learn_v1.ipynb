{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqHuqGsrDdSg+rscIBWzZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feiyoung/ReadPapers/blob/master/GNN_learn_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Attributed Graph neural network"
      ],
      "metadata": {
        "id": "V-uz9eOIpPAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GraphConvolutionLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolutionLayer, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
        "        torch.nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, x, adj_matrix):\n",
        "        support = torch.mm(x, self.weight)\n",
        "        output = torch.mm(adj_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GraphNeuralNetwork, self).__init__()\n",
        "        self.gc1 = GraphConvolutionLayer(input_size, hidden_size)\n",
        "        self.gc2 = GraphConvolutionLayer(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, adj_matrix):\n",
        "        x = F.relu(self.gc1(x, adj_matrix))\n",
        "        x = self.gc2(x, adj_matrix)\n",
        "        return x\n",
        "\n",
        "    def get_node_embeddings(self, x, adj_matrix):\n",
        "        # This method returns the node embeddings without the final activation function\n",
        "        x = F.relu(self.gc1(x, adj_matrix))\n",
        "        x = self.gc2(x, adj_matrix)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "N3Yps4mEoIsX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# Assuming you have an adjacency matrix (adj_matrix) and node features (x)\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 3  # Number of features for each node\n",
        "hidden_size = 64\n",
        "output_size = 16  # Adjust based on your task\n",
        "\n",
        "# Create an instance of the GraphNeuralNetwork\n",
        "gnn = GraphNeuralNetwork(input_size, hidden_size, output_size)\n",
        "\n",
        "# Example adjacency matrix (replace this with your actual adjacency matrix)\n",
        "adj_matrix = torch.tensor([[0.0, 0.5, 0.2],\n",
        "                          [0.5, 0.0, 0.8],\n",
        "                          [0.2, 0.8, 0.0]])\n",
        "\n",
        "# Example node features (replace this with your actual node features)\n",
        "x = torch.tensor([[1.0, 2.0, 3.0],\n",
        "                  [4.0, 5.0, 6.0],\n",
        "                  [7.0, 8.0, 9.0]])\n",
        "\n",
        "# Forward pass\n",
        "output = gnn(x, adj_matrix)\n",
        "\n",
        "# Get node embeddings\n",
        "node_embeddings = gnn.get_node_embeddings(x, adj_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSYn2oS_oOtI",
        "outputId": "5c9a3f0d-4ac8-43d1-b431-b0cbb9975c00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 9.7266e+01,  8.5493e+20, -1.6717e+02,  3.3610e+21,  1.2256e+02,\n",
            "          7.9884e+20, -1.7684e+02, -1.0007e+02, -5.8829e+00, -2.5528e+02,\n",
            "         -1.5681e+02,  4.5447e+30,  7.0062e+22,  4.7899e+01,  4.5447e+30,\n",
            "          7.0062e+22],\n",
            "        [ 1.7983e+02,  8.5493e+20, -3.0936e+02,  3.3610e+21,  2.2746e+02,\n",
            "          7.9884e+20, -3.2813e+02, -1.8593e+02, -8.8979e+00, -4.7509e+02,\n",
            "         -2.9133e+02,  4.5447e+30,  7.0062e+22,  8.9437e+01,  4.5447e+30,\n",
            "          7.0062e+22],\n",
            "        [ 1.3900e+02,  8.5493e+20, -2.3887e+02,  3.3610e+21,  1.7511e+02,\n",
            "          7.9884e+20, -2.5262e+02, -1.4296e+02, -8.5334e+00, -3.6462e+02,\n",
            "         -2.2401e+02,  4.5447e+30,  7.0062e+22,  6.8421e+01,  4.5447e+30,\n",
            "          7.0062e+22]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(node_embeddings)"
      ],
      "metadata": {
        "id": "3uIpMAqLohag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Use reconstruction error as the loss to train the GAT"
      ],
      "metadata": {
        "id": "zOjCb9m9pduN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GraphConvolutionLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolutionLayer, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
        "        torch.nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, x, adj_matrix):\n",
        "        support = torch.mm(x, self.weight)\n",
        "        output = torch.mm(adj_matrix, support) + self.bias\n",
        "        return output\n",
        "\n",
        "class GraphAutoencoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GraphAutoencoder, self).__init__()\n",
        "        self.gc_encoder = GraphConvolutionLayer(input_size, hidden_size)\n",
        "        self.gc_decoder = GraphConvolutionLayer(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x, adj_matrix):\n",
        "        # Encoder\n",
        "        encoded = F.relu(self.gc_encoder(x, adj_matrix))\n",
        "\n",
        "        # Decoder\n",
        "        decoded = self.gc_decoder(encoded, adj_matrix.t())  # Assuming undirected graph\n",
        "\n",
        "        return encoded, decoded\n",
        "\n"
      ],
      "metadata": {
        "id": "_UsxwOFfpicU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "# Assuming you have an adjacency matrix (adj_matrix) and node features (x)\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 3  # Number of features for each node\n",
        "hidden_size = 2\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "\n",
        "# Create an instance of the GraphAutoencoder\n",
        "autoencoder = GraphAutoencoder(input_size, hidden_size)\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "# Define the reconstruction loss function\n",
        "def reconstruction_loss(Z, A):\n",
        "    return torch.sum((torch.mm(Z, Z.t()) - torch.mm(A, A.t()))**2)\n",
        "\n",
        "# Example adjacency matrix (replace this with your actual adjacency matrix)\n",
        "adj_matrix = torch.tensor([[0.0, 0.5, 0.2],\n",
        "                          [0.5, 0.0, 0.8],\n",
        "                          [0.2, 0.8, 0.0]])\n",
        "\n",
        "# Example node features (replace this with your actual node features)\n",
        "x = torch.tensor([[1.0, 2.0, 3.0],\n",
        "                  [4.0, 5.0, 6.0],\n",
        "                  [7.0, 8.0, 9.0]])\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    encoded, decoded = autoencoder(x, adj_matrix)\n",
        "\n",
        "    # Reconstruction loss for adjacency matrix\n",
        "    adj_reconstruction_loss = reconstruction_loss(decoded, adj_matrix)\n",
        "\n",
        "    # Reconstruction loss for node features\n",
        "    attribute_reconstruction_loss = reconstruction_loss(encoded, x)\n",
        "\n",
        "    # Total loss\n",
        "    total_loss = adj_reconstruction_loss + attribute_reconstruction_loss\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Total Loss: {total_loss.item():.4f}')\n",
        "\n",
        "# Reconstruction after training\n",
        "encoded, decoded = autoencoder(x, adj_matrix)\n",
        "print(\"Original Adjacency Matrix:\")\n",
        "print(adj_matrix)\n",
        "print(\"Reconstructed Adjacency Matrix:\")\n",
        "print(decoded.detach().numpy())\n",
        "print(\"Original Node Features:\")\n",
        "print(x)\n",
        "print(\"Reconstructed Node Features:\")\n",
        "print(encoded.detach().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dB-EACQplDq",
        "outputId": "f66b081f-d229-4f61-fd6b-17e5d1a4cbd6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Total Loss: 29697666711552.0000\n",
            "Epoch [20/100], Total Loss: 29430309191680.0000\n",
            "Epoch [30/100], Total Loss: 29166275657728.0000\n",
            "Epoch [40/100], Total Loss: 28905698230272.0000\n",
            "Epoch [50/100], Total Loss: 28648583200768.0000\n",
            "Epoch [60/100], Total Loss: 28394848780288.0000\n",
            "Epoch [70/100], Total Loss: 28144400596992.0000\n",
            "Epoch [80/100], Total Loss: 27897108627456.0000\n",
            "Epoch [90/100], Total Loss: 27652847042560.0000\n",
            "Epoch [100/100], Total Loss: 27411523567616.0000\n",
            "Original Adjacency Matrix:\n",
            "tensor([[0.0000, 0.5000, 0.2000],\n",
            "        [0.5000, 0.0000, 0.8000],\n",
            "        [0.2000, 0.8000, 0.0000]])\n",
            "Reconstructed Adjacency Matrix:\n",
            "[[1288.0089       2.543558   123.26287  ]\n",
            " [1328.6759       3.942283   232.53368  ]\n",
            " [1308.0443       3.7181284  175.90778  ]]\n",
            "Original Node Features:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n",
            "Reconstructed Node Features:\n",
            "[[243.27205     5.7657104]\n",
            " [244.15155    10.330714 ]\n",
            " [243.36494     6.2428837]]\n"
          ]
        }
      ]
    }
  ]
}
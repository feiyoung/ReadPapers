{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feiyoung/ReadPapers/blob/master/%E2%80%9Cdaegc_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgfADKF32LZf"
      },
      "source": [
        "# DAEGC by pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZaditPc2S8G"
      },
      "source": [
        "A PyTorch implement of [Attributed Graph Clustering: A Deep Attentional Embedding Approach](https://www.ijcai.org/Proceedings/2019/0509.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1N3sx9JfJGM"
      },
      "source": [
        "## Result On Cora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2vBPxWgfFnT"
      },
      "source": [
        "|Model|ACC|NMI|F-score|ARI|\n",
        "|---|---|---|---|---|\n",
        "|DAEGC|0.704|0.528|0.682|0.496|\n",
        "|my DAEGC|0.707|0.543|0.693|0.484|\n",
        "\n",
        "*Didn't run kmeans 50 times to get average score for my implement*\n",
        "\n",
        "*Just take the best score*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RswNIuEZfNtq"
      },
      "source": [
        "## Result On Citeseer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRws_N7dfIdc"
      },
      "source": [
        "|Model|ACC|NMI|F-score|ARI|\n",
        "|---|---|---|---|---|\n",
        "|DAEGC|0.672|0.397|0.636|0.410|\n",
        "|my DAEGC|0.687|0.417|0.643|0.441|\n",
        "\n",
        "*Didn't run kmeans 50 times to get average score for my implement*\n",
        "\n",
        "*Just take the best score*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFmZsic5fjEh"
      },
      "source": [
        "## Prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peSnz3431xAp"
      },
      "source": [
        "### Check GPU and CUDA version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dofbUbVnmqCJ",
        "outputId": "17043724-b646-4c8e-854a-6fd218c3321a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar 22 01:45:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QNDfMOLRLmH",
        "outputId": "ec9ffa5d-4fcc-4dd1-ab22-c63e457688da"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdr0P3S2113f"
      },
      "source": [
        "### Install requirement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al2YJ_D1UOXN",
        "outputId": "4a498616-56a1-4817-87cd-7a57b6ba5b1e"
      },
      "source": [
        "%%bash\n",
        "#CUDA=cpu\n",
        "CUDA=cu110\n",
        "TORCH=1.7.0\n",
        "TORCHVISION=0.8.1\n",
        "\n",
        "echo BUILDING WITH CUDA===${CUDA} AND TORCH===${TORCH}\n",
        "python3 -m pip install torch==${TORCH}+${CUDA} torchvision==${TORCHVISION}+${CUDA} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "python3 -m pip install torch-scatter==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.html\n",
        "python3 -m pip install torch-sparse==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.html\n",
        "python3 -m pip install torch-cluster==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.html\n",
        "python3 -m pip install torch-spline-conv==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.html\n",
        "python3 -m pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BUILDING WITH CUDA===cu110 AND TORCH===1.7.0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 16.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement torch==1.7.0+cu110 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6)\n",
            "ERROR: No matching distribution found for torch==1.7.0+cu110\n",
            "ERROR: Could not find a version that satisfies the requirement torch-scatter==latest+cu110 (from versions: 0.3.0, 1.0.2, 1.0.3, 1.0.4, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.3.0, 1.3.1, 1.3.2, 1.4.0, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.1.0, 2.1.1, 2.1.2)\n",
            "ERROR: No matching distribution found for torch-scatter==latest+cu110\n",
            "ERROR: Could not find a version that satisfies the requirement torch-sparse==latest+cu110 (from versions: 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.5.1, 0.6.0, 0.6.1, 0.6.3, 0.6.4, 0.6.5, 0.6.6, 0.6.7, 0.6.8, 0.6.9, 0.6.10, 0.6.11, 0.6.12, 0.6.13, 0.6.14, 0.6.15, 0.6.16, 0.6.17, 0.6.18)\n",
            "ERROR: No matching distribution found for torch-sparse==latest+cu110\n",
            "ERROR: Could not find a version that satisfies the requirement torch-cluster==latest+cu110 (from versions: 0.1.1, 0.2.3, 0.2.4, 1.0.1, 1.0.3, 1.1.1, 1.1.2, 1.1.3, 1.1.4, 1.1.5, 1.2.1, 1.2.2, 1.2.3, 1.2.4, 1.3.0, 1.4.0, 1.4.1, 1.4.2, 1.4.3a1, 1.4.3, 1.4.4, 1.4.5, 1.5.2, 1.5.3, 1.5.4, 1.5.5, 1.5.6, 1.5.7, 1.5.8, 1.5.9, 1.6.0, 1.6.1, 1.6.2, 1.6.3)\n",
            "ERROR: No matching distribution found for torch-cluster==latest+cu110\n",
            "ERROR: Could not find a version that satisfies the requirement torch-spline-conv==latest+cu110 (from versions: 0.1.0, 1.0.0, 1.0.1, 1.0.3, 1.0.4, 1.0.5, 1.0.6, 1.1.0, 1.1.1, 1.2.0, 1.2.1, 1.2.2)\n",
            "ERROR: No matching distribution found for torch-spline-conv==latest+cu110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-kj9V9knE6b",
        "outputId": "12cc0a18-04ee-4f8c-8583-862743de15cb"
      },
      "source": [
        "%%bash\n",
        "pip3 install munkres\n",
        "pip3 install -U scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting munkres\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: munkres\n",
            "Successfully installed munkres-1.1.4\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 70.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlXGY0VU1-MS"
      },
      "source": [
        "### Download code from github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnEF1AvVmFX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b76e0b6-04ca-4473-fc6f-aebb105508ad"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/Tiger101010/DAEGC.git\n",
        "mkdir /content/DAEGC/DAEGC/pretrain\n",
        "rm -rf /content/sample_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'DAEGC'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyHZLznRouem"
      },
      "source": [
        "## Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = utils.get_dataset(args.name)\n",
        "dataset = datasets[0]"
      ],
      "metadata": {
        "id": "gVZ3nY0fYkOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIUJYNgGbRhm"
      },
      "source": [
        "### Cora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "4TvCaDBWe0Q0",
        "outputId": "4c895ad6-d68d-47e0-8185-8b3afeada0f6"
      },
      "source": [
        "%%bash\n",
        "cd /content/DAEGC/DAEGC\n",
        "python3 pretrain.py --name Cora --max_epoch 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use cuda: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/DAEGC/DAEGC/pretrain.py\", line 78, in <module>\n",
            "    dataset = datasets[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py\", line 263, in __getitem__\n",
            "    data = self.get(self.indices()[idx])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py\", line 97, in get\n",
            "    return copy.copy(self._data)\n",
            "  File \"/usr/lib/python3.10/copy.py\", line 84, in copy\n",
            "    return copier(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\", line 511, in __copy__\n",
            "    out.__dict__['_store'] = copy.copy(self._store)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\", line 477, in __getattr__\n",
            "    raise RuntimeError(\n",
            "RuntimeError: The 'data' object was created by an older version of PyG. If this error occurred while loading an already existing dataset, remove the 'processed/' directory in the dataset's root folder and try again.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-248879d54ae6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cd /content/DAEGC/DAEGC\\npython3 pretrain.py --name Cora --max_epoch 50\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cd /content/DAEGC/DAEGC\\npython3 pretrain.py --name Cora --max_epoch 50\\n'' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_fIaMlcJK8"
      },
      "source": [
        "### Citeseer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcGgq1gDX3Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k5bjtJCaNU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21eef8a2-95c4-46b0-c139-e15c6cdb3f0e"
      },
      "source": [
        "%%bash\n",
        "cd /content/DAEGC/DAEGC\n",
        "python3 pretrain.py --name Citeseer --max_epoch 50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use cuda: True\n",
            "Namespace(alpha=0.2, cuda=True, embedding_size=16, hidden_size=256, input_dim=3703, k=None, lr=0.005, max_epoch=50, n_clusters=6, name='Citeseer', weight_decay=0.005)\n",
            "GAT(\n",
            "  (conv1): GATLayer (3703 -> 256)\n",
            "  (conv2): GATLayer (256 -> 16)\n",
            ")\n",
            "epoch 0:acc 0.3303, nmi 0.1065, ari 0.0883, f1 0.3097\n",
            "epoch 1:acc 0.3883, nmi 0.1517, ari 0.1280, f1 0.3711\n",
            "epoch 2:acc 0.4788, nmi 0.2179, ari 0.1969, f1 0.4601\n",
            "epoch 3:acc 0.5029, nmi 0.2466, ari 0.2240, f1 0.4838\n",
            "epoch 4:acc 0.5242, nmi 0.2689, ari 0.2467, f1 0.5002\n",
            "epoch 5:acc 0.5437, nmi 0.2957, ari 0.2715, f1 0.5168\n",
            "epoch 6:acc 0.5573, nmi 0.3102, ari 0.2865, f1 0.5282\n",
            "epoch 7:acc 0.5654, nmi 0.3201, ari 0.2964, f1 0.5354\n",
            "epoch 8:acc 0.5693, nmi 0.3324, ari 0.3059, f1 0.5371\n",
            "epoch 9:acc 0.5756, nmi 0.3407, ari 0.3148, f1 0.5446\n",
            "epoch 10:acc 0.5753, nmi 0.3449, ari 0.3151, f1 0.5453\n",
            "epoch 11:acc 0.5852, nmi 0.3549, ari 0.3274, f1 0.5547\n",
            "epoch 12:acc 0.5840, nmi 0.3551, ari 0.3283, f1 0.5542\n",
            "epoch 13:acc 0.5858, nmi 0.3529, ari 0.3295, f1 0.5552\n",
            "epoch 14:acc 0.5888, nmi 0.3532, ari 0.3241, f1 0.5540\n",
            "epoch 15:acc 0.6177, nmi 0.3659, ari 0.3520, f1 0.5813\n",
            "epoch 16:acc 0.6213, nmi 0.3661, ari 0.3547, f1 0.5834\n",
            "epoch 17:acc 0.6171, nmi 0.3614, ari 0.3510, f1 0.5804\n",
            "epoch 18:acc 0.6231, nmi 0.3672, ari 0.3576, f1 0.5859\n",
            "epoch 19:acc 0.6237, nmi 0.3693, ari 0.3562, f1 0.5843\n",
            "epoch 20:acc 0.6189, nmi 0.3648, ari 0.3497, f1 0.5791\n",
            "epoch 21:acc 0.6204, nmi 0.3684, ari 0.3531, f1 0.5789\n",
            "epoch 22:acc 0.6207, nmi 0.3724, ari 0.3566, f1 0.5800\n",
            "epoch 23:acc 0.6168, nmi 0.3757, ari 0.3567, f1 0.5792\n",
            "epoch 24:acc 0.6132, nmi 0.3784, ari 0.3593, f1 0.5785\n",
            "epoch 25:acc 0.6078, nmi 0.3799, ari 0.3588, f1 0.5758\n",
            "epoch 26:acc 0.6035, nmi 0.3807, ari 0.3583, f1 0.5743\n",
            "epoch 27:acc 0.6041, nmi 0.3820, ari 0.3596, f1 0.5756\n",
            "epoch 28:acc 0.6087, nmi 0.3851, ari 0.3630, f1 0.5801\n",
            "epoch 29:acc 0.6201, nmi 0.3902, ari 0.3717, f1 0.5902\n",
            "epoch 30:acc 0.6246, nmi 0.3953, ari 0.3785, f1 0.5939\n",
            "epoch 31:acc 0.6351, nmi 0.4020, ari 0.3879, f1 0.6031\n",
            "epoch 32:acc 0.6342, nmi 0.3991, ari 0.3857, f1 0.6022\n",
            "epoch 33:acc 0.6138, nmi 0.3967, ari 0.3769, f1 0.5875\n",
            "epoch 34:acc 0.6210, nmi 0.3973, ari 0.3800, f1 0.5958\n",
            "epoch 35:acc 0.6171, nmi 0.3934, ari 0.3775, f1 0.5928\n",
            "epoch 36:acc 0.6267, nmi 0.3931, ari 0.3802, f1 0.5997\n",
            "epoch 37:acc 0.6294, nmi 0.3931, ari 0.3824, f1 0.6017\n",
            "epoch 38:acc 0.6285, nmi 0.3925, ari 0.3819, f1 0.6000\n",
            "epoch 39:acc 0.6348, nmi 0.3940, ari 0.3857, f1 0.6051\n",
            "epoch 40:acc 0.6441, nmi 0.3959, ari 0.3922, f1 0.6123\n",
            "epoch 41:acc 0.6516, nmi 0.3983, ari 0.3990, f1 0.6174\n",
            "epoch 42:acc 0.6345, nmi 0.3882, ari 0.3862, f1 0.6037\n",
            "epoch 43:acc 0.6372, nmi 0.3867, ari 0.3870, f1 0.6054\n",
            "epoch 44:acc 0.6330, nmi 0.3825, ari 0.3823, f1 0.6022\n",
            "epoch 45:acc 0.6324, nmi 0.3801, ari 0.3816, f1 0.6000\n",
            "epoch 46:acc 0.6201, nmi 0.3714, ari 0.3684, f1 0.5918\n",
            "epoch 47:acc 0.6303, nmi 0.3654, ari 0.3743, f1 0.5917\n",
            "epoch 48:acc 0.6044, nmi 0.3614, ari 0.3534, f1 0.5777\n",
            "epoch 49:acc 0.6486, nmi 0.3844, ari 0.3891, f1 0.6038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULJUQsUWcMIg"
      },
      "source": [
        "### Pubmed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4cx-oHDR5Rm"
      },
      "source": [
        "%%bash\n",
        "cd /content/DAEGC/DAEGC\n",
        "python3 pretrain.py --name PubMed --max_epoch 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYGW8NnOopY4"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYsj9saYcQCg"
      },
      "source": [
        "### Cora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMCu2v1XeD8F"
      },
      "source": [
        "|Model|ACC|NMI|F-score|ARI|\n",
        "|---|---|---|---|---|\n",
        "|DAEGC|0.704|0.528|0.682|0.496|\n",
        "|my DAEGC|0.707|0.543|0.693|0.484|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PpClcyki9au",
        "outputId": "9d33c73d-59f2-4297-da90-e840590bdd84"
      },
      "source": [
        "%%bash\n",
        "cd /content/DAEGC/DAEGC\n",
        "python3 daegc.py --update_interval 5 --name Cora --epoch 29 --max_epoch 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use cuda: True\n",
            "Namespace(alpha=0.2, cuda=True, embedding_size=16, epoch=29, hidden_size=256, input_dim=1433, k=None, lr=0.0001, max_epoch=200, n_clusters=7, name='Cora', pretrain_path='./pretrain/predaegc_Cora_29.pkl', update_interval=5, weight_decay=0.005)\n",
            "DAEGC(\n",
            "  (gat): GAT(\n",
            "    (conv1): GATLayer (1433 -> 256)\n",
            "    (conv2): GATLayer (256 -> 16)\n",
            "  )\n",
            ")\n",
            "epoch pretrain:acc 0.7068, nmi 0.5237, ari 0.4746, f1 0.6907\n",
            "epoch 0:acc 0.7068, nmi 0.5237, ari 0.4746, f1 0.6907\n",
            "epoch 5:acc 0.7075, nmi 0.5269, ari 0.4756, f1 0.6929\n",
            "epoch 10:acc 0.7086, nmi 0.5307, ari 0.4784, f1 0.6940\n",
            "epoch 15:acc 0.7075, nmi 0.5323, ari 0.4779, f1 0.6931\n",
            "epoch 20:acc 0.7068, nmi 0.5316, ari 0.4786, f1 0.6914\n",
            "epoch 25:acc 0.7057, nmi 0.5319, ari 0.4786, f1 0.6901\n",
            "epoch 30:acc 0.7083, nmi 0.5362, ari 0.4834, f1 0.6928\n",
            "epoch 35:acc 0.7072, nmi 0.5357, ari 0.4822, f1 0.6919\n",
            "epoch 40:acc 0.7064, nmi 0.5357, ari 0.4812, f1 0.6914\n",
            "epoch 45:acc 0.7064, nmi 0.5381, ari 0.4817, f1 0.6919\n",
            "epoch 50:acc 0.7075, nmi 0.5393, ari 0.4834, f1 0.6931\n",
            "epoch 55:acc 0.7072, nmi 0.5389, ari 0.4822, f1 0.6931\n",
            "epoch 60:acc 0.7075, nmi 0.5405, ari 0.4831, f1 0.6934\n",
            "epoch 65:acc 0.7075, nmi 0.5403, ari 0.4838, f1 0.6931\n",
            "epoch 70:acc 0.7072, nmi 0.5396, ari 0.4836, f1 0.6930\n",
            "epoch 75:acc 0.7057, nmi 0.5394, ari 0.4818, f1 0.6920\n",
            "epoch 80:acc 0.7057, nmi 0.5393, ari 0.4817, f1 0.6920\n",
            "epoch 85:acc 0.7053, nmi 0.5397, ari 0.4807, f1 0.6921\n",
            "epoch 90:acc 0.7049, nmi 0.5391, ari 0.4798, f1 0.6915\n",
            "epoch 95:acc 0.7057, nmi 0.5402, ari 0.4806, f1 0.6923\n",
            "epoch 100:acc 0.7049, nmi 0.5398, ari 0.4793, f1 0.6918\n",
            "epoch 105:acc 0.7046, nmi 0.5392, ari 0.4789, f1 0.6911\n",
            "epoch 110:acc 0.7072, nmi 0.5411, ari 0.4818, f1 0.6938\n",
            "epoch 115:acc 0.7072, nmi 0.5410, ari 0.4809, f1 0.6942\n",
            "epoch 120:acc 0.7064, nmi 0.5416, ari 0.4798, f1 0.6940\n",
            "epoch 125:acc 0.7075, nmi 0.5431, ari 0.4813, f1 0.6953\n",
            "epoch 130:acc 0.7072, nmi 0.5428, ari 0.4805, f1 0.6950\n",
            "epoch 135:acc 0.7064, nmi 0.5424, ari 0.4792, f1 0.6946\n",
            "epoch 140:acc 0.7061, nmi 0.5417, ari 0.4787, f1 0.6940\n",
            "epoch 145:acc 0.7061, nmi 0.5419, ari 0.4777, f1 0.6945\n",
            "epoch 150:acc 0.7057, nmi 0.5423, ari 0.4774, f1 0.6941\n",
            "epoch 155:acc 0.7057, nmi 0.5421, ari 0.4773, f1 0.6941\n",
            "epoch 160:acc 0.7057, nmi 0.5413, ari 0.4764, f1 0.6943\n",
            "epoch 165:acc 0.7053, nmi 0.5408, ari 0.4756, f1 0.6941\n",
            "epoch 170:acc 0.7064, nmi 0.5422, ari 0.4767, f1 0.6955\n",
            "epoch 175:acc 0.7064, nmi 0.5416, ari 0.4759, f1 0.6956\n",
            "epoch 180:acc 0.7057, nmi 0.5414, ari 0.4751, f1 0.6949\n",
            "epoch 185:acc 0.7061, nmi 0.5416, ari 0.4754, f1 0.6953\n",
            "epoch 190:acc 0.7068, nmi 0.5423, ari 0.4764, f1 0.6959\n",
            "epoch 195:acc 0.7053, nmi 0.5396, ari 0.4752, f1 0.6941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WrjwRgTcTRK"
      },
      "source": [
        "### Citeseer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNbRHRQ_cdCI"
      },
      "source": [
        "|Model|ACC|NMI|F-score|ARI|\n",
        "|---|---|---|---|---|\n",
        "|DAEGC|0.672|0.397|0.636|0.410|\n",
        "|my DAEGC|0.687|0.417|0.643|0.441|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFOBF7OsmnyB",
        "outputId": "3f2e2e2e-cc89-487b-da29-0c872256d7d5"
      },
      "source": [
        "%%bash\n",
        "cd /content/DAEGC/DAEGC\n",
        "python3 daegc.py --update_interval 5 --name Citeseer --epoch 41 --max_epoch 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use cuda: True\n",
            "Namespace(alpha=0.2, cuda=True, embedding_size=16, epoch=41, hidden_size=256, input_dim=3703, k=None, lr=0.0001, max_epoch=200, n_clusters=6, name='Citeseer', pretrain_path='./pretrain/predaegc_Citeseer_41.pkl', update_interval=5, weight_decay=0.005)\n",
            "DAEGC(\n",
            "  (gat): GAT(\n",
            "    (conv1): GATLayer (3703 -> 256)\n",
            "    (conv2): GATLayer (256 -> 16)\n",
            "  )\n",
            ")\n",
            "epoch pretrain:acc 0.6748, nmi 0.4005, ari 0.4207, f1 0.6295\n",
            "epoch 0:acc 0.6748, nmi 0.4005, ari 0.4207, f1 0.6295\n",
            "epoch 5:acc 0.6775, nmi 0.4062, ari 0.4259, f1 0.6318\n",
            "epoch 10:acc 0.6772, nmi 0.4048, ari 0.4259, f1 0.6314\n",
            "epoch 15:acc 0.6814, nmi 0.4098, ari 0.4311, f1 0.6374\n",
            "epoch 20:acc 0.6826, nmi 0.4118, ari 0.4335, f1 0.6384\n",
            "epoch 25:acc 0.6832, nmi 0.4116, ari 0.4341, f1 0.6393\n",
            "epoch 30:acc 0.6850, nmi 0.4138, ari 0.4368, f1 0.6413\n",
            "epoch 35:acc 0.6868, nmi 0.4160, ari 0.4399, f1 0.6425\n",
            "epoch 40:acc 0.6874, nmi 0.4174, ari 0.4412, f1 0.6430\n",
            "epoch 45:acc 0.6895, nmi 0.4197, ari 0.4442, f1 0.6453\n",
            "epoch 50:acc 0.6871, nmi 0.4170, ari 0.4413, f1 0.6425\n",
            "epoch 55:acc 0.6853, nmi 0.4152, ari 0.4391, f1 0.6404\n",
            "epoch 60:acc 0.6850, nmi 0.4150, ari 0.4388, f1 0.6401\n",
            "epoch 65:acc 0.6853, nmi 0.4153, ari 0.4393, f1 0.6403\n",
            "epoch 70:acc 0.6847, nmi 0.4148, ari 0.4390, f1 0.6394\n",
            "epoch 75:acc 0.6847, nmi 0.4144, ari 0.4387, f1 0.6394\n",
            "epoch 80:acc 0.6850, nmi 0.4148, ari 0.4391, f1 0.6397\n",
            "epoch 85:acc 0.6847, nmi 0.4143, ari 0.4387, f1 0.6394\n",
            "epoch 90:acc 0.6847, nmi 0.4143, ari 0.4386, f1 0.6398\n",
            "epoch 95:acc 0.6847, nmi 0.4143, ari 0.4386, f1 0.6398\n",
            "epoch 100:acc 0.6844, nmi 0.4147, ari 0.4389, f1 0.6393\n",
            "epoch 105:acc 0.6844, nmi 0.4149, ari 0.4389, f1 0.6393\n",
            "epoch 110:acc 0.6850, nmi 0.4151, ari 0.4397, f1 0.6399\n",
            "epoch 115:acc 0.6847, nmi 0.4151, ari 0.4397, f1 0.6396\n",
            "epoch 120:acc 0.6847, nmi 0.4152, ari 0.4397, f1 0.6395\n",
            "epoch 125:acc 0.6847, nmi 0.4153, ari 0.4399, f1 0.6394\n",
            "epoch 130:acc 0.6850, nmi 0.4158, ari 0.4404, f1 0.6397\n",
            "epoch 135:acc 0.6847, nmi 0.4150, ari 0.4398, f1 0.6394\n",
            "epoch 140:acc 0.6850, nmi 0.4152, ari 0.4400, f1 0.6401\n",
            "epoch 145:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 150:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 155:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 160:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 165:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 170:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 175:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 180:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 185:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 190:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n",
            "epoch 195:acc 0.6850, nmi 0.4154, ari 0.4403, f1 0.6400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfiw1Ok7cVYI"
      },
      "source": [
        "### Pubmed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI7aj6scR_IY"
      },
      "source": [
        "%%bash\n",
        "cd /content/DAEGC/DAEGC\n",
        "python3 daegc.py --update_interval 5 --name PubMed --epoch 25 --max_epoch 200"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}